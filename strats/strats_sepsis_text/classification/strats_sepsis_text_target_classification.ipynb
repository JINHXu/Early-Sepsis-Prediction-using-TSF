{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTDFCBgnk1o3"
   },
   "source": [
    "# Strats+Text Target Task\n",
    "\n",
    "- binary classification\n",
    "\n",
    "- physiological features + clinical text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECKAJiLXiTlN"
   },
   "source": [
    "## Hardware check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e7odgm5VsOsb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 27 01:21:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    38W / 300W |     10MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    39W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    39W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    38W / 300W |      9MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2397      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    1   N/A  N/A      2397      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    2   N/A  N/A      2397      G   /usr/libexec/Xorg                   8MiB |\n",
      "|    3   N/A  N/A      2397      G   /usr/libexec/Xorg                   8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oEEUeIW3sOsc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of cores\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count() \n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY9I5eXWeOom"
   },
   "source": [
    "## Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 01:21:26.470530: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-27 01:21:26.564167: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 01:21:40.990423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras import models\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import pandas as pd\n",
    "import json\n",
    "import smart_cond as sc\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfKWDkwoeSGU"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_path = 'preprocessed_sepsis_data_with_text_sepsis_removed.pkl'\n",
    "# pkl = pickle.load(open(data_path, 'rb'))\n",
    "# # pkl = pd.read_pickle(data_path)\n",
    "# data = pkl[0]\n",
    "# oc = pkl[1]\n",
    "# # old_train_ind = pkl[2]\n",
    "# # old_valid_ind = pkl[3]\n",
    "# test_ind = pkl[4]\n",
    "# del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# oc = oc.sort_values(by='ts_ind').reset_index()\n",
    "# oc\n",
    "# x = []\n",
    "# y = []\n",
    "# for row in oc.itertuples():\n",
    "#     if row.ts_ind not in test_ind:\n",
    "#         x.append(row.ts_ind)\n",
    "#         y.append(row.in_hospital_sepsis)\n",
    "# x = np.array(x)\n",
    "# y = np.array(y)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train_ind, valid_ind, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "# # dump to pkl\n",
    "# pickle.dump([train_ind, valid_ind, test_ind], open('text_target_inds.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # load patient ids\n",
    "# train_patients_data = pd.read_csv('train.csv')\n",
    "# train_patients = train_patients_data['patient_id'].to_list()\n",
    "\n",
    "# test_patients_data = pd.read_csv('test.csv')\n",
    "# test_patients = test_patients_data['patient_id'].to_list()\n",
    "\n",
    "# valid_patients_data = pd.read_csv('val.csv')\n",
    "# valid_patients = valid_patients_data['patient_id'].to_list()\n",
    "\n",
    "# # get ts_inds from ids\n",
    "# ids = oc['SUBJECT_ID'].tolist()\n",
    "\n",
    "# # train\n",
    "# train_ind = []\n",
    "# ts_ind = oc['ts_ind'].tolist()\n",
    "# for i in range(len(ts_ind)):\n",
    "#     if ids[i] in train_patients:\n",
    "#         train_ind.append(ts_ind[i])\n",
    "# train_ind = np.array(train_ind)\n",
    "\n",
    "# # test\n",
    "# test_ind = []\n",
    "# for i in range(len(ts_ind)):\n",
    "#     if ids[i] in test_patients:\n",
    "#         test_ind.append(ts_ind[i])\n",
    "# test_ind = np.array(test_ind)\n",
    "\n",
    "# # valid\n",
    "# valid_ind = []\n",
    "# for i in range(len(ts_ind)):\n",
    "#     if ids[i] in valid_patients:\n",
    "#         valid_ind.append(ts_ind[i])\n",
    "# # to np.array\n",
    "# valid_ind = np.array(valid_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'preprocessed_sepsis_data_with_text_sepsis_removed.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "# pkl = pd.read_pickle(data_path)\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "# train_ind = pkl[2]\n",
    "# valid_ind = pkl[3]\n",
    "# test_ind = pkl[4]\n",
    "del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'text_target_inds.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "train_ind = pkl[0]\n",
    "valid_ind = pkl[1]\n",
    "test_ind = pkl[2]\n",
    "del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114564it [00:00, 808996.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19267073it [00:21, 877734.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter labeled data in first 24h.\n",
    "data = data.loc[data.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "data = data.loc[(data.hour>=0)&(data.hour<=24)]\n",
    "oc = oc.loc[oc.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "# Get y and N.\n",
    "y = np.array(oc.sort_values(by='ts_ind')['in_hospital_sepsis']).astype('float32')\n",
    "N = data.ts_ind.max() + 1\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds==0)*1 + (stds!=0)*stds\n",
    "demo = (demo-means)/stds\n",
    "# Trim to max len.\n",
    "data = data.sample(frac=1)\n",
    "data = data.groupby('ts_ind').head(880)\n",
    "# Get N, V, var_to_ind.\n",
    "N = data.ts_ind.max() + 1\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Add obs index.\n",
    "data = data.sort_values(by=['ts_ind']).reset_index(drop=True)\n",
    "data = data.reset_index().rename(columns={'index':'obs_ind'})\n",
    "data = data.merge(data.groupby('ts_ind').agg({'obs_ind':'min'}).reset_index().rename(columns={ \\\n",
    "                                                            'obs_ind':'first_obs_ind'}), on='ts_ind')\n",
    "data['obs_ind'] = data['obs_ind'] - data['first_obs_ind']\n",
    "# Find max_len.\n",
    "max_len = data.obs_ind.max()+1\n",
    "print ('max_len', max_len)\n",
    "# Generate times_ip and values_ip matrices.\n",
    "# times_inp = np.zeros((N, max_len), dtype='float32')\n",
    "# values_inp = np.zeros((N, max_len), dtype='float32')\n",
    "# varis_inp = np.zeros((N, max_len), dtype='int32')\n",
    "texts_inp = np.empty([N, max_len], dtype=object)\n",
    "for row in tqdm(data.itertuples()):\n",
    "    ts_ind = row.ts_ind\n",
    "    l = row.obs_ind\n",
    "    # times_inp[ts_ind, l] = row.hour\n",
    "    if isinstance(row.value, str):\n",
    "        # values_inp[ts_ind, l] = 1.0\n",
    "        texts_inp[ts_ind, l] = row.value\n",
    "    else:\n",
    "        # values_inp[ts_ind, l] = row.value\n",
    "        texts_inp[ts_ind, l] = ''\n",
    "    # varis_inp[ts_ind, l] = row.vind\n",
    "    \n",
    "data.drop(columns=['obs_ind', 'first_obs_ind'], inplace=True)\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "# train_ip = [ip[train_ind] for ip in [demo, times_inp, values_inp, varis_inp, texts_inp]]\n",
    "# valid_ip = [ip[valid_ind] for ip in [demo, times_inp, values_inp, varis_inp, texts_inp]]\n",
    "# test_ip = [ip[test_ind] for ip in [demo, times_inp, values_inp, varis_inp, texts_inp]]\n",
    "# del times_inp, values_inp, varis_inp\n",
    "train_ip = [ip[train_ind] for ip in [texts_inp]]\n",
    "valid_ip = [ip[valid_ind] for ip in [texts_inp]]\n",
    "test_ip = [ip[test_ind] for ip in [texts_inp]]\n",
    "del texts_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_texts = train_ip[0]\n",
    "valid_texts = valid_ip[0]\n",
    "test_texts = test_ip[0]\n",
    "del train_ip, valid_ip, test_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37460/37460 [00:01<00:00, 33848.42it/s]\n"
     ]
    }
   ],
   "source": [
    "concat_train_texts = []\n",
    "for train_text in tqdm(train_texts):\n",
    "    train_text = train_text[train_text != None]\n",
    "    train_text = train_text[train_text != '']\n",
    "    concat_text = ' '.join(list(train_text))\n",
    "    concat_train_texts.append(concat_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9365/9365 [00:00<00:00, 34247.50it/s]\n"
     ]
    }
   ],
   "source": [
    "concat_valid_texts = []\n",
    "for valid_text in tqdm(valid_texts):\n",
    "    valid_text = valid_text[valid_text != None]\n",
    "    valid_text = valid_text[valid_text != '']\n",
    "    concat_text = ' '.join(list(valid_text))\n",
    "    concat_valid_texts.append(concat_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10457/10457 [00:00<00:00, 38153.42it/s]\n"
     ]
    }
   ],
   "source": [
    "concat_test_texts = []\n",
    "for test_text in tqdm(test_texts):\n",
    "    test_text = test_text[test_text != None]\n",
    "    test_text = test_text[test_text != '']\n",
    "    concat_text = ' '.join(list(test_text))\n",
    "    concat_test_texts.append(concat_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train_texts, valid_texts, test_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from simpletransformers.language_representation import RepresentationModel\n",
    "from simpletransformers.config.model_args import ModelArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForTextRepresentation: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTextRepresentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTextRepresentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArgs(max_seq_length=512, silent = False)\n",
    "model = RepresentationModel(\n",
    "    \"bert\", \"emilyalsentzer/Bio_ClinicalBERT\", args=model_args)\n",
    "train_text_features = model.encode_sentences(concat_train_texts, combine_strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForTextRepresentation: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTextRepresentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTextRepresentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArgs(max_seq_length=512, silent = False)\n",
    "model = RepresentationModel(\n",
    "    \"bert\", \"emilyalsentzer/Bio_ClinicalBERT\", args=model_args)\n",
    "valid_text_features = model.encode_sentences(concat_valid_texts, combine_strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForTextRepresentation: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTextRepresentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTextRepresentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArgs(max_seq_length=512, silent = False)\n",
    "model = RepresentationModel(\n",
    "    \"bert\", \"emilyalsentzer/Bio_ClinicalBERT\", args=model_args)\n",
    "test_text_features = model.encode_sentences(concat_test_texts, combine_strategy=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dump to json just in case\n",
    "pickle.dump([train_text_features, valid_text_features, test_text_features], open('text_features_target.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del concat_train_texts, concat_valid_texts, concat_test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'text_features_target.pkl'\n",
    "train_text_features, valid_text_features, test_text_features = pickle.load(open(data_path, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'preprocessed_sepsis_data_with_text_sepsis_removed.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "# pkl = pd.read_pickle(data_path)\n",
    "data = pkl[0]\n",
    "oc = pkl[1]\n",
    "# train_ind = pkl[2]\n",
    "# valid_ind = pkl[3]\n",
    "# test_ind = pkl[4]\n",
    "del pkl\n",
    "data_path = 'text_target_inds.pkl'\n",
    "pkl = pickle.load(open(data_path, 'rb'))\n",
    "train_ind = pkl[0]\n",
    "valid_ind = pkl[1]\n",
    "test_ind = pkl[2]\n",
    "del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_path = 'strats_sepsis_text.pkl'\n",
    "# pkl = pickle.load(open(data_path, 'rb'))\n",
    "# train_ind = pkl[2]\n",
    "# valid_ind = pkl[3]\n",
    "# test_ind = pkl[4]\n",
    "# del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>hour</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>TABLE</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10223</td>\n",
       "      <td>467.816667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18407</td>\n",
       "      <td>28.016667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40300</td>\n",
       "      <td>155.166667</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23747</td>\n",
       "      <td>52.383333</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2357</td>\n",
       "      <td>73.133333</td>\n",
       "      <td>Text</td>\n",
       "      <td>1</td>\n",
       "      <td>noteevents</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886223</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>MBP</td>\n",
       "      <td>0.195381</td>\n",
       "      <td>chart</td>\n",
       "      <td>78.552377</td>\n",
       "      <td>17.645628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886224</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>O2 Saturation</td>\n",
       "      <td>-0.678068</td>\n",
       "      <td>chart</td>\n",
       "      <td>96.820961</td>\n",
       "      <td>4.160290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886225</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>RR</td>\n",
       "      <td>0.179866</td>\n",
       "      <td>chart</td>\n",
       "      <td>26.278501</td>\n",
       "      <td>15.130729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886226</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>SBP</td>\n",
       "      <td>-0.404061</td>\n",
       "      <td>chart</td>\n",
       "      <td>120.239648</td>\n",
       "      <td>25.341836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82886227</th>\n",
       "      <td>57281</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>Urine</td>\n",
       "      <td>-0.24296</td>\n",
       "      <td>output</td>\n",
       "      <td>123.393012</td>\n",
       "      <td>137.442433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82447326 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ts_ind        hour       variable     value       TABLE        mean  \\\n",
       "0          10223  467.816667           Text         1  noteevents    1.000000   \n",
       "1          18407   28.016667           Text         1  noteevents    1.000000   \n",
       "2          40300  155.166667           Text         1  noteevents    1.000000   \n",
       "3          23747   52.383333           Text         1  noteevents    1.000000   \n",
       "4           2357   73.133333           Text         1  noteevents    1.000000   \n",
       "...          ...         ...            ...       ...         ...         ...   \n",
       "82886223   57281   20.400000            MBP  0.195381       chart   78.552377   \n",
       "82886224   57281   20.400000  O2 Saturation -0.678068       chart   96.820961   \n",
       "82886225   57281   20.400000             RR  0.179866       chart   26.278501   \n",
       "82886226   57281   20.400000            SBP -0.404061       chart  120.239648   \n",
       "82886227   57281   20.400000          Urine  -0.24296      output  123.393012   \n",
       "\n",
       "                 std  \n",
       "0           1.000000  \n",
       "1           1.000000  \n",
       "2           1.000000  \n",
       "3           1.000000  \n",
       "4           1.000000  \n",
       "...              ...  \n",
       "82886223   17.645628  \n",
       "82886224    4.160290  \n",
       "82886225   15.130729  \n",
       "82886226   25.341836  \n",
       "82886227  137.442433  \n",
       "\n",
       "[82447326 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['variable'] == 'Text', 'value'] = 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "114564it [00:00, 813722.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len 880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19267073it [00:25, 754140.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter labeled data in first 24h.\n",
    "data = data.loc[data.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "data = data.loc[(data.hour>=0)&(data.hour<=24)]\n",
    "oc = oc.loc[oc.ts_ind.isin(np.concatenate((train_ind, valid_ind, test_ind), axis=-1))]\n",
    "# Fix age.\n",
    "data.loc[(data.variable=='Age')&(data.value>200), 'value'] = 91.4\n",
    "# Get y and N.\n",
    "y = np.array(oc.sort_values(by='ts_ind')['in_hospital_sepsis']).astype('float32')\n",
    "N = data.ts_ind.max() + 1\n",
    "# Get static data with mean fill and missingness indicator.\n",
    "static_varis = ['Age', 'Gender']\n",
    "ii = data.variable.isin(static_varis)\n",
    "static_data = data.loc[ii]\n",
    "data = data.loc[~ii]\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "static_var_to_ind = inv_list(static_varis)\n",
    "D = len(static_varis)\n",
    "demo = np.zeros((N, D))\n",
    "for row in tqdm(static_data.itertuples()):\n",
    "    demo[row.ts_ind, static_var_to_ind[row.variable]] = row.value\n",
    "# Normalize static data.\n",
    "means = demo.mean(axis=0, keepdims=True)\n",
    "stds = demo.std(axis=0, keepdims=True)\n",
    "stds = (stds==0)*1 + (stds!=0)*stds\n",
    "demo = (demo-means)/stds\n",
    "# Trim to max len.\n",
    "data = data.sample(frac=1)\n",
    "data = data.groupby('ts_ind').head(880)\n",
    "# Get N, V, var_to_ind.\n",
    "N = data.ts_ind.max() + 1\n",
    "varis = sorted(list(set(data.variable)))\n",
    "V = len(varis)\n",
    "def inv_list(l, start=0):\n",
    "    d = {}\n",
    "    for i in range(len(l)):\n",
    "        d[l[i]] = i+start\n",
    "    return d\n",
    "var_to_ind = inv_list(varis, start=1)\n",
    "data['vind'] = data.variable.map(var_to_ind)\n",
    "data = data[['ts_ind', 'vind', 'hour', 'value']].sort_values(by=['ts_ind', 'vind', 'hour'])\n",
    "# Add obs index.\n",
    "data = data.sort_values(by=['ts_ind']).reset_index(drop=True)\n",
    "data = data.reset_index().rename(columns={'index':'obs_ind'})\n",
    "data = data.merge(data.groupby('ts_ind').agg({'obs_ind':'min'}).reset_index().rename(columns={ \\\n",
    "                                                            'obs_ind':'first_obs_ind'}), on='ts_ind')\n",
    "data['obs_ind'] = data['obs_ind'] - data['first_obs_ind']\n",
    "# Find max_len.\n",
    "max_len = data.obs_ind.max()+1\n",
    "print ('max_len', max_len)\n",
    "# Generate times_ip and values_ip matrices.\n",
    "times_inp = np.zeros((N, max_len), dtype='float32')\n",
    "values_inp = np.zeros((N, max_len), dtype='float32')\n",
    "varis_inp = np.zeros((N, max_len), dtype='int32')\n",
    "for row in tqdm(data.itertuples()):\n",
    "    ts_ind = row.ts_ind\n",
    "    l = row.obs_ind\n",
    "    times_inp[ts_ind, l] = row.hour\n",
    "    values_inp[ts_ind, l] = row.value\n",
    "    varis_inp[ts_ind, l] = row.vind\n",
    "data.drop(columns=['obs_ind', 'first_obs_ind'], inplace=True)\n",
    "# Generate 3 sets of inputs and outputs.\n",
    "train_ip = [ip[train_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "valid_ip = [ip[valid_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "test_ip = [ip[test_ind] for ip in [demo, times_inp, values_inp, varis_inp]]\n",
    "del times_inp, values_inp, varis_inp\n",
    "train_op = y[train_ind]\n",
    "valid_op = y[valid_ind]\n",
    "test_op = y[test_ind]\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ip.append(train_text_features)\n",
    "valid_ip.append(valid_text_features)\n",
    "test_ip.append(test_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_path = 'preprocessed_sepsis_data_with_text_sepsis_removed.pkl'\n",
    "# pkl = pickle.load(open(data_path, 'rb'))\n",
    "# # pkl = pd.read_pickle(data_path)\n",
    "# data = pkl[0]\n",
    "# oc = pkl[1]\n",
    "# # train_ind = pkl[2]\n",
    "# # valid_ind = pkl[3]\n",
    "# # test_ind = pkl[4]\n",
    "# del pkl\n",
    "# data_path = 'text_target_inds.pkl'\n",
    "# pkl = pickle.load(open(data_path, 'rb'))\n",
    "# train_ind = pkl[0]\n",
    "# valid_ind = pkl[1]\n",
    "# test_ind = pkl[2]\n",
    "# del pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>in_hospital_sepsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>110404</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>188028</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>173727</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>164716</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>158689</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54862</th>\n",
       "      <td>57277</td>\n",
       "      <td>182476</td>\n",
       "      <td>83967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29333</th>\n",
       "      <td>57278</td>\n",
       "      <td>118320</td>\n",
       "      <td>23200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54573</th>\n",
       "      <td>57279</td>\n",
       "      <td>146497</td>\n",
       "      <td>73807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14317</th>\n",
       "      <td>57280</td>\n",
       "      <td>118512</td>\n",
       "      <td>10762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>57281</td>\n",
       "      <td>122737</td>\n",
       "      <td>4094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57282 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ts_ind  HADM_ID  SUBJECT_ID  in_hospital_sepsis\n",
       "0           0   110404         268                   1\n",
       "1           1   188028         270                   0\n",
       "2           2   173727         271                   0\n",
       "3           3   164716         272                   0\n",
       "4           4   158689         273                   0\n",
       "...       ...      ...         ...                 ...\n",
       "54862   57277   182476       83967                   0\n",
       "29333   57278   118320       23200                   0\n",
       "54573   57279   146497       73807                   0\n",
       "14317   57280   118512       10762                   0\n",
       "4430    57281   122737        4094                   0\n",
       "\n",
       "[57282 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oc = oc.sort_values(by='ts_ind')\n",
    "# oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ts_ind</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>in_hospital_sepsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110404</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188028</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>173727</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>164716</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>158689</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57277</th>\n",
       "      <td>54862</td>\n",
       "      <td>57277</td>\n",
       "      <td>182476</td>\n",
       "      <td>83967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57278</th>\n",
       "      <td>29333</td>\n",
       "      <td>57278</td>\n",
       "      <td>118320</td>\n",
       "      <td>23200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57279</th>\n",
       "      <td>54573</td>\n",
       "      <td>57279</td>\n",
       "      <td>146497</td>\n",
       "      <td>73807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57280</th>\n",
       "      <td>14317</td>\n",
       "      <td>57280</td>\n",
       "      <td>118512</td>\n",
       "      <td>10762</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57281</th>\n",
       "      <td>4430</td>\n",
       "      <td>57281</td>\n",
       "      <td>122737</td>\n",
       "      <td>4094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57282 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  ts_ind  HADM_ID  SUBJECT_ID  in_hospital_sepsis\n",
       "0          0       0   110404         268                   1\n",
       "1          1       1   188028         270                   0\n",
       "2          2       2   173727         271                   0\n",
       "3          3       3   164716         272                   0\n",
       "4          4       4   158689         273                   0\n",
       "...      ...     ...      ...         ...                 ...\n",
       "57277  54862   57277   182476       83967                   0\n",
       "57278  29333   57278   118320       23200                   0\n",
       "57279  54573   57279   146497       73807                   0\n",
       "57280  14317   57280   118512       10762                   0\n",
       "57281   4430   57281   122737        4094                   0\n",
       "\n",
       "[57282 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset_oc = oc.reset_index()\n",
    "# reset_oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_op = reset_oc['in_hospital_sepsis'][train_ind]\n",
    "# valid_op = reset_oc['in_hospital_sepsis'][valid_ind]\n",
    "# test_op = reset_oc['in_hospital_sepsis'][test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_op = train_op.to_numpy(dtype='float32')\n",
    "# valid_op = valid_op.to_numpy(dtype='float32')\n",
    "# test_op = test_op.to_numpy(dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_res(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    minrp = np.minimum(precision, recall).max()\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    return [roc_auc, pr_auc, minrp]\n",
    "\n",
    "######################################################################################################## \n",
    "######################################################################################################## \n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=[0,1], y=train_op)\n",
    "def mortality_loss(y_true, y_pred):\n",
    "    sample_weights = (1-y_true)*class_weights[0] + y_true*class_weights[1]\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    return K.mean(sample_weights*bce, axis=-1)\n",
    "######################################################################################################## \n",
    "######################################################################################################## \n",
    "\n",
    "# var_weights = np.sum(fore_train_op[:, V:], axis=0)\n",
    "# var_weights[var_weights==0] = var_weights.max()\n",
    "# var_weights = var_weights.max()/var_weights\n",
    "# var_weights = var_weights.reshape((1, V))\n",
    "def forecast_loss(y_true, y_pred):\n",
    "    return K.sum(y_true[:,V:]*(y_true[:,:V]-y_pred)**2, axis=-1)\n",
    "\n",
    "def get_min_loss(weight):\n",
    "    def min_loss(y_true, y_pred):\n",
    "        return weight*y_pred\n",
    "    return min_loss\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def __init__(self, validation_data, batch_size):\n",
    "        self.val_x, self.val_y = validation_data\n",
    "        self.batch_size = batch_size\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.val_x, verbose=0, batch_size=self.batch_size)\n",
    "        if type(y_pred)==type([]):\n",
    "            y_pred = y_pred[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(self.val_y, y_pred)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        roc_auc = roc_auc_score(self.val_y, y_pred)\n",
    "        logs['custom_metric'] = pr_auc + roc_auc\n",
    "        print ('val_aucs:', pr_auc, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Embedding, Activation, Dropout, Softmax, Layer, InputSpec, Input, Dense, Lambda, TimeDistributed, Concatenate, Add\n",
    "from tensorflow.keras import initializers, regularizers, constraints, Model\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow import nn\n",
    "\n",
    "    \n",
    "class CVE(Layer):\n",
    "    def __init__(self, hid_units, output_dim):\n",
    "        self.hid_units = hid_units\n",
    "        self.output_dim = output_dim\n",
    "        super(CVE, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape): \n",
    "        self.W1 = self.add_weight(name='CVE_W1',\n",
    "                            shape=(1, self.hid_units),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        self.b1 = self.add_weight(name='CVE_b1',\n",
    "                            shape=(self.hid_units,),\n",
    "                            initializer='zeros',\n",
    "                            trainable=True)\n",
    "        self.W2 = self.add_weight(name='CVE_W2',\n",
    "                            shape=(self.hid_units, self.output_dim),\n",
    "                            initializer='glorot_uniform',\n",
    "                            trainable=True)\n",
    "        super(CVE, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = K.expand_dims(x, axis=-1)\n",
    "        x = K.dot(K.tanh(K.bias_add(K.dot(x, self.W1), self.b1)), self.W2)\n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape + (self.output_dim,)\n",
    "    \n",
    "    \n",
    "class Attention(Layer):\n",
    "    \n",
    "    def __init__(self, hid_dim):\n",
    "        self.hid_dim = hid_dim\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        self.W = self.add_weight(shape=(d, self.hid_dim), name='Att_W',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.hid_dim,), name='Att_b',\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(shape=(self.hid_dim,1), name='Att_u',\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e30):\n",
    "        attn_weights = K.dot(K.tanh(K.bias_add(K.dot(x,self.W), self.b)), self.u)\n",
    "        mask = K.expand_dims(mask, axis=-1)\n",
    "        attn_weights = mask*attn_weights + (1-mask)*mask_value\n",
    "        attn_weights = K.softmax(attn_weights, axis=-2)\n",
    "        return attn_weights\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1] + (1,)\n",
    "    \n",
    "    \n",
    "class Transformer(Layer):\n",
    "    \n",
    "    def __init__(self, N=2, h=8, dk=None, dv=None, dff=None, dropout=0):\n",
    "        self.N, self.h, self.dk, self.dv, self.dff, self.dropout = N, h, dk, dv, dff, dropout\n",
    "        self.epsilon = K.epsilon() * K.epsilon()\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d = input_shape.as_list()[-1]\n",
    "        if self.dk==None:\n",
    "            self.dk = d//self.h\n",
    "        if self.dv==None:\n",
    "            self.dv = d//self.h\n",
    "        if self.dff==None:\n",
    "            self.dff = 2*d\n",
    "        self.Wq = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wq',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wk = self.add_weight(shape=(self.N, self.h, d, self.dk), name='Wk',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wv = self.add_weight(shape=(self.N, self.h, d, self.dv), name='Wv',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.Wo = self.add_weight(shape=(self.N, self.dv*self.h, d), name='Wo',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.W1 = self.add_weight(shape=(self.N, d, self.dff), name='W1',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b1 = self.add_weight(shape=(self.N, self.dff), name='b1',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.W2 = self.add_weight(shape=(self.N, self.dff, d), name='W2',\n",
    "                                 initializer='glorot_uniform', trainable=True)\n",
    "        self.b2 = self.add_weight(shape=(self.N, d), name='b2',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        self.gamma = self.add_weight(shape=(2*self.N,), name='gamma',\n",
    "                                 initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(shape=(2*self.N,), name='beta',\n",
    "                                 initializer='zeros', trainable=True)\n",
    "        super(Transformer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask, mask_value=-1e-30):\n",
    "        mask = K.expand_dims(mask, axis=-2)\n",
    "        for i in range(self.N):\n",
    "            # MHA\n",
    "            mha_ops = []\n",
    "            for j in range(self.h):\n",
    "                q = K.dot(x, self.Wq[i,j,:,:])\n",
    "                k = K.permute_dimensions(K.dot(x, self.Wk[i,j,:,:]), (0,2,1))\n",
    "                v = K.dot(x, self.Wv[i,j,:,:])\n",
    "                A = K.batch_dot(q,k)\n",
    "                # Mask unobserved steps.\n",
    "                A = mask*A + (1-mask)*mask_value\n",
    "                # Mask for attention dropout.\n",
    "                def dropped_A():\n",
    "                    dp_mask = K.cast((K.random_uniform(shape=array_ops.shape(A))>=self.dropout), K.floatx())\n",
    "                    return A*dp_mask + (1-dp_mask)*mask_value\n",
    "                A = sc.smart_cond(K.learning_phase(), dropped_A, lambda: array_ops.identity(A))\n",
    "                A = K.softmax(A, axis=-1)\n",
    "                mha_ops.append(K.batch_dot(A,v))\n",
    "            conc = K.concatenate(mha_ops, axis=-1)\n",
    "            proj = K.dot(conc, self.Wo[i,:,:])\n",
    "            # Dropout.\n",
    "            proj = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(proj, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(proj))\n",
    "            # Add & LN\n",
    "            x = x+proj\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i] + self.beta[2*i]\n",
    "            # FFN\n",
    "            ffn_op = K.bias_add(K.dot(K.relu(K.bias_add(K.dot(x, self.W1[i,:,:]), self.b1[i,:])), \n",
    "                           self.W2[i,:,:]), self.b2[i,:,])\n",
    "            # Dropout.\n",
    "            ffn_op = sc.smart_cond(K.learning_phase(), lambda: array_ops.identity(nn.dropout(ffn_op, rate=self.dropout)),\\\n",
    "                                       lambda: array_ops.identity(ffn_op))\n",
    "            # Add & LN\n",
    "            x = x+ffn_op\n",
    "            mean = K.mean(x, axis=-1, keepdims=True)\n",
    "            variance = K.mean(K.square(x - mean), axis=-1, keepdims=True)\n",
    "            std = K.sqrt(variance + self.epsilon)\n",
    "            x = (x - mean) / std\n",
    "            x = x*self.gamma[2*i+1] + self.beta[2*i+1]            \n",
    "        return x\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "def build_strats(D, max_len, V, d, N, he, dropout, forecast=False):\n",
    "    demo = Input(shape=(D,))\n",
    "    demo_enc = Dense(2*d, activation='tanh')(demo)\n",
    "    demo_enc = Dense(d, activation='tanh')(demo_enc)\n",
    "    varis = Input(shape=(max_len,))\n",
    "    values = Input(shape=(max_len,))\n",
    "    times = Input(shape=(max_len,))\n",
    "    varis_emb = Embedding(V+1, d)(varis)\n",
    "    cve_units = int(np.sqrt(d))\n",
    "    values_emb = CVE(cve_units, d)(values)\n",
    "    times_emb = CVE(cve_units, d)(times)\n",
    "    comb_emb = Add()([varis_emb, values_emb, times_emb]) # b, L, d\n",
    "#     demo_enc = Lambda(lambda x:K.expand_dims(x, axis=-2))(demo_enc) # b, 1, d\n",
    "#     comb_emb = Concatenate(axis=-2)([demo_enc, comb_emb]) # b, L+1, d\n",
    "    mask = Lambda(lambda x:K.clip(x,0,1))(varis) # b, L\n",
    "#     mask = Lambda(lambda x:K.concatenate((K.ones_like(x)[:,0:1], x), axis=-1))(mask) # b, L+1\n",
    "    cont_emb = Transformer(N, he, dk=None, dv=None, dff=None, dropout=dropout)(comb_emb, mask=mask)\n",
    "    attn_weights = Attention(2*d)(cont_emb, mask=mask)\n",
    "    fused_emb = Lambda(lambda x:K.sum(x[0]*x[1], axis=-2))([cont_emb, attn_weights])\n",
    "    # embed text input\n",
    "    texts = Input(shape=(768,))\n",
    "    text_enc = Dense(2*d, activation='tanh')(texts)\n",
    "    text_enc = Dense(d, activation='tanh')(text_enc)\n",
    "    conc = Concatenate(axis=-1)([fused_emb, text_enc, demo_enc])\n",
    "    fore_op = Dense(V)(conc)\n",
    "    op = Dense(1, activation='sigmoid')(fore_op)\n",
    "    model = Model([demo, times, values, varis, texts], op)\n",
    "    if forecast:\n",
    "        fore_model = Model([demo, times, values, varis, texts], fore_op)\n",
    "        return [model, fore_model]\n",
    "    return model\n",
    "\n",
    "# To tune:\n",
    "# 1. Transformer parameters. (N, h, dropout)\n",
    "# 2. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 10\n",
      "Num train: 3746 Num valid: 936\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_10ld.h5\n",
      "Epoch 1/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.5550val_aucs: 0.4508572914407443 0.8615160907664638\n",
      "118/118 [==============================] - 14s 63ms/step - loss: 0.5550 - custom_metric: 1.3124\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4400val_aucs: 0.46805386924497794 0.8808913378997181\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.4400 - custom_metric: 1.3489\n",
      "Epoch 3/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3937val_aucs: 0.4756138396377966 0.8817331853722625\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.3937 - custom_metric: 1.3573\n",
      "Epoch 4/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3611val_aucs: 0.45883030932377106 0.8747688108266687\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.3611 - custom_metric: 1.3336\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3354val_aucs: 0.48324001766223085 0.8845776094082833\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3354 - custom_metric: 1.3678\n",
      "Epoch 6/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2751val_aucs: 0.4760481662579533 0.8663886018954324\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2751 - custom_metric: 1.3424\n",
      "Epoch 7/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2588val_aucs: 0.45622755302590356 0.870725391905509\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2588 - custom_metric: 1.3270\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1843val_aucs: 0.4386338992083671 0.8574599165805685\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1843 - custom_metric: 1.2961\n",
      "Epoch 9/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1732val_aucs: 0.446329595414285 0.8558527532238933\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1732 - custom_metric: 1.3022\n",
      "Epoch 10/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1195val_aucs: 0.38875151665124436 0.8423831936631845\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.1195 - custom_metric: 1.2311\n",
      "Epoch 11/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1663val_aucs: 0.4864225315124314 0.8649345017155831\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.1662 - custom_metric: 1.3514\n",
      "Epoch 12/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.0986val_aucs: 0.431463460266451 0.8552532557813237\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0986 - custom_metric: 1.2867\n",
      "Epoch 13/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.0855val_aucs: 0.44321878381818225 0.8506996262707432\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0855 - custom_metric: 1.2939\n",
      "Epoch 14/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.0680val_aucs: 0.40728980819509814 0.8494751208561334\n",
      "118/118 [==============================] - 5s 47ms/step - loss: 0.0680 - custom_metric: 1.2568\n",
      "Epoch 15/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.0391val_aucs: 0.41809459982732644 0.8609165933238945\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.0391 - custom_metric: 1.2790\n",
      "Test res 0.8634965874680818 0.41765642645475604 0.44545454545454544\n",
      "Repeat 1 ld 10\n",
      "Num train: 3746 Num valid: 936\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_10ld.h5\n",
      "Epoch 1/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.5686val_aucs: 0.42539218039703863 0.8592527386541471\n",
      "118/118 [==============================] - 14s 62ms/step - loss: 0.5686 - custom_metric: 1.2846\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4288val_aucs: 0.41959170177115707 0.8640873015873016\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.4288 - custom_metric: 1.2837\n",
      "Epoch 3/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3883val_aucs: 0.441350329086125 0.8588195841716967\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.3882 - custom_metric: 1.3002\n",
      "Epoch 4/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3487val_aucs: 0.4458156104523332 0.8613346747149564\n",
      "118/118 [==============================] - 6s 46ms/step - loss: 0.3487 - custom_metric: 1.3072\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2978val_aucs: 0.4089116335641689 0.8465655041359268\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2978 - custom_metric: 1.2555\n",
      "Epoch 6/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2651val_aucs: 0.44152898919769645 0.8585820478426112\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2651 - custom_metric: 1.3001\n",
      "Epoch 7/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2135val_aucs: 0.41964375822453803 0.8398865414710486\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2135 - custom_metric: 1.2595\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2120val_aucs: 0.3859108677765943 0.8342555331991952\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2120 - custom_metric: 1.2202\n",
      "Epoch 9/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1577val_aucs: 0.371349807475889 0.8403616141292198\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1577 - custom_metric: 1.2117\n",
      "Epoch 10/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1384val_aucs: 0.41297047815331206 0.8396210596914822\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1384 - custom_metric: 1.2526\n",
      "Epoch 11/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1136val_aucs: 0.3712859683989651 0.8391180415828303\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1136 - custom_metric: 1.2104\n",
      "Epoch 12/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1137val_aucs: 0.39598685442085113 0.8478649675832775\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1137 - custom_metric: 1.2439\n",
      "Epoch 13/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1154val_aucs: 0.4005259762544233 0.8370221327967807\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1154 - custom_metric: 1.2375\n",
      "Epoch 14/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.0502val_aucs: 0.3832497225853405 0.8436452045606974\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.0502 - custom_metric: 1.2269\n",
      "Test res 0.867254525520423 0.41544530015652353 0.43281938325991187\n",
      "Repeat 2 ld 10\n",
      "Num train: 3746 Num valid: 936\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_10ld.h5\n",
      "Epoch 1/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.5199val_aucs: 0.5303976509710558 0.880132397084048\n",
      "118/118 [==============================] - 14s 63ms/step - loss: 0.5199 - custom_metric: 1.4105\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4144val_aucs: 0.5743033527390328 0.9034760934819897\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.4144 - custom_metric: 1.4778\n",
      "Epoch 3/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3863val_aucs: 0.5574123056813403 0.8991209262435678\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.3863 - custom_metric: 1.4565\n",
      "Epoch 4/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3152val_aucs: 0.5460966948775665 0.898383897941681\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.3152 - custom_metric: 1.4445\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2938val_aucs: 0.5355424273791675 0.8894993567753001\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2938 - custom_metric: 1.4250\n",
      "Epoch 6/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2473val_aucs: 0.5252013644231849 0.8888293310463121\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2473 - custom_metric: 1.4140\n",
      "Epoch 7/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2404val_aucs: 0.516060183766687 0.883817538593482\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2404 - custom_metric: 1.3999\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2130val_aucs: 0.5340335252981921 0.8932649013722127\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2130 - custom_metric: 1.4273\n",
      "Epoch 9/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1710val_aucs: 0.4694797875913352 0.8810838336192109\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1710 - custom_metric: 1.3506\n",
      "Epoch 10/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1305val_aucs: 0.5120799919826102 0.8677771226415094\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1305 - custom_metric: 1.3799\n",
      "Epoch 11/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1697val_aucs: 0.49205429569747816 0.8786985420240138\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1697 - custom_metric: 1.3708\n",
      "Epoch 12/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1346val_aucs: 0.5183894826355695 0.8751742066895369\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1346 - custom_metric: 1.3936\n",
      "Test res 0.8728738122585361 0.44874789664310527 0.44886363636363635\n",
      "Repeat 3 ld 10\n",
      "Num train: 3746 Num valid: 936\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_10ld.h5\n",
      "Epoch 1/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.5344val_aucs: 0.43685934120100384 0.8659409988762979\n",
      "118/118 [==============================] - 14s 62ms/step - loss: 0.5344 - custom_metric: 1.3028\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4311val_aucs: 0.4505208699300577 0.8681071713848612\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.4311 - custom_metric: 1.3186\n",
      "Epoch 3/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3798val_aucs: 0.4472950877578335 0.8675114739450063\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.3798 - custom_metric: 1.3148\n",
      "Epoch 4/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3734val_aucs: 0.44895732302208274 0.8593070955688233\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3734 - custom_metric: 1.3083\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3316val_aucs: 0.45115692117938333 0.8648579126220164\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3316 - custom_metric: 1.3160\n",
      "Epoch 6/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2994val_aucs: 0.4484506172890034 0.8625428157534896\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2994 - custom_metric: 1.3110\n",
      "Epoch 7/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2582val_aucs: 0.4442214673582802 0.8447802011832718\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2582 - custom_metric: 1.2890\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2229val_aucs: 0.4393463955443582 0.8420454083912108\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2229 - custom_metric: 1.2814\n",
      "Epoch 9/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1817val_aucs: 0.44195103728616275 0.8588603224889323\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1817 - custom_metric: 1.3008\n",
      "Epoch 10/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1951val_aucs: 0.3540666891391768 0.8093632806682642\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1951 - custom_metric: 1.1634\n",
      "Epoch 11/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2359val_aucs: 0.4069113737773418 0.8360342796799481\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2359 - custom_metric: 1.2429\n",
      "Epoch 12/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1872val_aucs: 0.38812130981696225 0.8366570542761598\n",
      "118/118 [==============================] - 5s 47ms/step - loss: 0.1872 - custom_metric: 1.2248\n",
      "Test res 0.8737702544922968 0.4375452247267857 0.4445701357466063\n",
      "Repeat 4 ld 10\n",
      "Num train: 3746 Num valid: 936\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_10ld.h5\n",
      "Epoch 1/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.5017val_aucs: 0.41710057437163334 0.8531652219595482\n",
      "118/118 [==============================] - 14s 61ms/step - loss: 0.5017 - custom_metric: 1.2703\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4068val_aucs: 0.42794753717232803 0.8559232991857104\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.4068 - custom_metric: 1.2839\n",
      "Epoch 3/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3730val_aucs: 0.4491683183971482 0.8622012083004992\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3730 - custom_metric: 1.3114\n",
      "Epoch 4/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3307val_aucs: 0.4485197998466086 0.8685841870239033\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3307 - custom_metric: 1.3171\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3095val_aucs: 0.4024711458390569 0.8492645127396901\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3095 - custom_metric: 1.2517\n",
      "Epoch 6/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3069val_aucs: 0.4646982411522611 0.8521801943787759\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.3068 - custom_metric: 1.3169\n",
      "Epoch 7/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2435val_aucs: 0.44249589705878073 0.8566456527449436\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2435 - custom_metric: 1.2991\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2085val_aucs: 0.4102240300482354 0.8482532177567638\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2085 - custom_metric: 1.2585\n",
      "Epoch 9/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1902val_aucs: 0.4252695439252771 0.848909902810612\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1902 - custom_metric: 1.2742\n",
      "Epoch 10/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1813val_aucs: 0.3798250470568317 0.847097452061991\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1813 - custom_metric: 1.2269\n",
      "Epoch 11/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1602val_aucs: 0.3693012445333834 0.821565537168374\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1602 - custom_metric: 1.1909\n",
      "Epoch 12/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1348val_aucs: 0.33965932467242754 0.8163777252429736\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.1347 - custom_metric: 1.1560\n",
      "Epoch 13/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1098val_aucs: 0.40351697977651546 0.8273180982400842\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1098 - custom_metric: 1.2308\n",
      "Epoch 14/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1177val_aucs: 0.3908411462672296 0.8255187811925401\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.1178 - custom_metric: 1.2164\n",
      "Test res 0.8573656582532012 0.40927943475088285 0.4431818181818182\n",
      "Repeat 5 ld 10\n",
      "Num train: 3746 Num valid: 936\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_10ld.h5\n",
      "Epoch 1/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.5255val_aucs: 0.40000357204769027 0.8586740654205607\n",
      "118/118 [==============================] - 13s 61ms/step - loss: 0.5255 - custom_metric: 1.2587\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3987val_aucs: 0.42367428407416463 0.8484959112149532\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.3987 - custom_metric: 1.2722\n",
      "Epoch 3/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3519val_aucs: 0.43433543375908606 0.8500730140186916\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3519 - custom_metric: 1.2844\n",
      "Epoch 4/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3141val_aucs: 0.4354541943125886 0.8496057242990654\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.3140 - custom_metric: 1.2851\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2779val_aucs: 0.42063309676650595 0.8410630841121495\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2779 - custom_metric: 1.2617\n",
      "Epoch 6/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2298val_aucs: 0.4140955698563414 0.8404935747663552\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2298 - custom_metric: 1.2546\n",
      "Epoch 7/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2353val_aucs: 0.39214369896833456 0.8421728971962618\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2353 - custom_metric: 1.2343\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1748val_aucs: 0.394497206971007 0.8444801401869159\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1748 - custom_metric: 1.2390\n",
      "Epoch 9/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1598val_aucs: 0.3805232550935427 0.836945093457944\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1598 - custom_metric: 1.2175\n",
      "Epoch 10/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1612val_aucs: 0.3828031579787341 0.8213054906542057\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1612 - custom_metric: 1.2041\n",
      "Epoch 11/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1383val_aucs: 0.34259637351123584 0.808863901869159\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1383 - custom_metric: 1.1515\n",
      "Epoch 12/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1079val_aucs: 0.3570083913795568 0.8328271028037384\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.1079 - custom_metric: 1.1898\n",
      "Epoch 13/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.0918val_aucs: 0.327030170433983 0.8219772196261682\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0918 - custom_metric: 1.1490\n",
      "Epoch 14/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.0669val_aucs: 0.33594525741382025 0.825598714953271\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.0670 - custom_metric: 1.1615\n",
      "Test res 0.8677017380656308 0.4212652162648804 0.46136363636363636\n",
      "Repeat 6 ld 10\n",
      "Num train: 3746 Num valid: 936\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_10ld.h5\n",
      "Epoch 1/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.5661val_aucs: 0.3590437666283366 0.8615272969172851\n",
      "118/118 [==============================] - 14s 63ms/step - loss: 0.5661 - custom_metric: 1.2206\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4366val_aucs: 0.3856429089913225 0.8679527690004989\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.4366 - custom_metric: 1.2536\n",
      "Epoch 3/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4225val_aucs: 0.3968813944754523 0.8776741302934551\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.4225 - custom_metric: 1.2746\n",
      "Epoch 4/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3704val_aucs: 0.4116008087674322 0.8744991911464555\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.3704 - custom_metric: 1.2861\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3222val_aucs: 0.4079939757250555 0.8662292306064134\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.3222 - custom_metric: 1.2742\n",
      "Epoch 6/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3002val_aucs: 0.3799839673338783 0.8631601227643138\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3002 - custom_metric: 1.2431\n",
      "Epoch 7/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2560val_aucs: 0.3995017857201097 0.8740909846846981\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2560 - custom_metric: 1.2736\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2176val_aucs: 0.3989030244224454 0.8687994194396987\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2176 - custom_metric: 1.2677\n",
      "Epoch 9/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.3334val_aucs: 0.3251459740020174 0.836732534055002\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.3333 - custom_metric: 1.1619\n",
      "Epoch 10/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2010val_aucs: 0.32464112848521876 0.8321061941550882\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.2009 - custom_metric: 1.1567\n",
      "Epoch 11/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1477val_aucs: 0.34077561928976524 0.8500521597145578\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1477 - custom_metric: 1.1908\n",
      "Epoch 12/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1177val_aucs: 0.33403041927609156 0.8528037736419576\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1177 - custom_metric: 1.1868\n",
      "Epoch 13/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1407val_aucs: 0.3119801170854362 0.834751976777588\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1407 - custom_metric: 1.1467\n",
      "Epoch 14/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1027val_aucs: 0.34586623209032796 0.832136431670774\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1027 - custom_metric: 1.1780\n",
      "Test res 0.8718704020997277 0.4506066170550519 0.4590909090909091\n",
      "Repeat 7 ld 10\n",
      "Num train: 3746 Num valid: 936\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_10ld.h5\n",
      "Epoch 1/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.5271val_aucs: 0.37659286069886594 0.8637833867709996\n",
      "118/118 [==============================] - 13s 61ms/step - loss: 0.5271 - custom_metric: 1.2404\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4182val_aucs: 0.39066600234427235 0.8798570601279678\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.4182 - custom_metric: 1.2705\n",
      "Epoch 3/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3685val_aucs: 0.4113343148663001 0.8817638667212813\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.3685 - custom_metric: 1.2931\n",
      "Epoch 4/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3347val_aucs: 0.40676545910314565 0.8721027133151598\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.3347 - custom_metric: 1.2789\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3204val_aucs: 0.4123501755333924 0.883882540713852\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3204 - custom_metric: 1.2962\n",
      "Epoch 6/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2658val_aucs: 0.4033691898497664 0.8742213873077304\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2658 - custom_metric: 1.2776\n",
      "Epoch 7/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2271val_aucs: 0.3840184736187954 0.8684020960748032\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2271 - custom_metric: 1.2524\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2000val_aucs: 0.3782338173555728 0.863755137784432\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2000 - custom_metric: 1.2420\n",
      "Epoch 9/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1787val_aucs: 0.39870996527846025 0.8628794192008362\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1787 - custom_metric: 1.2616\n",
      "Epoch 10/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1369val_aucs: 0.3353421248138526 0.8555346826932584\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1369 - custom_metric: 1.1909\n",
      "Epoch 11/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1352val_aucs: 0.35099245927948497 0.8468339948304354\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1352 - custom_metric: 1.1978\n",
      "Epoch 12/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1503val_aucs: 0.3738806014510488 0.8636845153180129\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1503 - custom_metric: 1.2376\n",
      "Epoch 13/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.0941val_aucs: 0.35871282216792605 0.8518764389327532\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0941 - custom_metric: 1.2106\n",
      "Epoch 14/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1206val_aucs: 0.35018763026448146 0.8482323196655319\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1206 - custom_metric: 1.1984\n",
      "Epoch 15/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1675val_aucs: 0.3698211502234493 0.8601392675037783\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1675 - custom_metric: 1.2300\n",
      "Test res 0.8736024756281623 0.4526998733322249 0.4647727272727273\n",
      "Repeat 8 ld 10\n",
      "Num train: 3746 Num valid: 936\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_10ld.h5\n",
      "Epoch 1/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4823val_aucs: 0.48391940023593283 0.8791208791208791\n",
      "118/118 [==============================] - 14s 61ms/step - loss: 0.4823 - custom_metric: 1.3630\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3803val_aucs: 0.46436951635005497 0.8763118538266468\n",
      "118/118 [==============================] - 6s 49ms/step - loss: 0.3803 - custom_metric: 1.3407\n",
      "Epoch 3/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3271val_aucs: 0.4979897550201072 0.8851680863515182\n",
      "118/118 [==============================] - 6s 48ms/step - loss: 0.3271 - custom_metric: 1.3832\n",
      "Epoch 4/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3091val_aucs: 0.4797753797445017 0.8805383965147279\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.3091 - custom_metric: 1.3603\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2782val_aucs: 0.5182158657615727 0.8810325768905649\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2782 - custom_metric: 1.3992\n",
      "Epoch 6/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2216val_aucs: 0.4758474864940581 0.8769100721763443\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2216 - custom_metric: 1.3528\n",
      "Epoch 7/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1920val_aucs: 0.5096976440826437 0.8732947525846935\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1920 - custom_metric: 1.3830\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1410val_aucs: 0.4383703040259975 0.8592236166200663\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1410 - custom_metric: 1.2976\n",
      "Epoch 9/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1107val_aucs: 0.46911051793150327 0.843422849340009\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1107 - custom_metric: 1.3125\n",
      "Epoch 10/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1310val_aucs: 0.47370433636790893 0.8687170817348332\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1310 - custom_metric: 1.3424\n",
      "Epoch 11/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1290val_aucs: 0.40955389639811934 0.8551401261460434\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1290 - custom_metric: 1.2647\n",
      "Epoch 12/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.0841val_aucs: 0.4276525853360513 0.8551271213993107\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0841 - custom_metric: 1.2828\n",
      "Epoch 13/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.0496val_aucs: 0.41465050253069013 0.8564666103127643\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0496 - custom_metric: 1.2711\n",
      "Epoch 14/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.0290val_aucs: 0.3900991928442781 0.8528773002145783\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0290 - custom_metric: 1.2430\n",
      "Epoch 15/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.0781val_aucs: 0.4271581037112584 0.856739709994148\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.0781 - custom_metric: 1.2839\n",
      "Test res 0.8665142339126886 0.412434208237357 0.44154370034052215\n",
      "Repeat 9 ld 10\n",
      "Num train: 3746 Num valid: 936\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_10ld.h5\n",
      "Epoch 1/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4965val_aucs: 0.49043518846398604 0.9012650085763293\n",
      "118/118 [==============================] - 14s 63ms/step - loss: 0.4965 - custom_metric: 1.3917\n",
      "Epoch 2/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.4288val_aucs: 0.5275316079701852 0.9062768010291595\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.4288 - custom_metric: 1.4338\n",
      "Epoch 3/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3760val_aucs: 0.4991360551789781 0.8879180960548885\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3760 - custom_metric: 1.3871\n",
      "Epoch 4/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3377val_aucs: 0.5328986496710791 0.8923804674099485\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.3377 - custom_metric: 1.4253\n",
      "Epoch 5/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.3257val_aucs: 0.5350187402284863 0.8895261578044598\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.3257 - custom_metric: 1.4245\n",
      "Epoch 6/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2730val_aucs: 0.5165102909222679 0.888668524871355\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.2730 - custom_metric: 1.4052\n",
      "Epoch 7/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.2933val_aucs: 0.5222188506844911 0.8826114922813035\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.2933 - custom_metric: 1.4048\n",
      "Epoch 8/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.2257val_aucs: 0.5269685304569245 0.8718910806174958\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.2257 - custom_metric: 1.3989\n",
      "Epoch 9/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1862val_aucs: 0.502236801074755 0.8725343053173241\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1862 - custom_metric: 1.3748\n",
      "Epoch 10/1000\n",
      "117/118 [============================>.] - ETA: 0s - loss: 0.1530val_aucs: 0.5375875714673398 0.8819146655231561\n",
      "118/118 [==============================] - 5s 45ms/step - loss: 0.1529 - custom_metric: 1.4195\n",
      "Epoch 11/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1334val_aucs: 0.5082474542408509 0.8712210548885078\n",
      "118/118 [==============================] - 6s 47ms/step - loss: 0.1334 - custom_metric: 1.3795\n",
      "Epoch 12/1000\n",
      "118/118 [==============================] - ETA: 0s - loss: 0.1001val_aucs: 0.5131998127799079 0.8689295668953688\n",
      "118/118 [==============================] - 5s 46ms/step - loss: 0.1001 - custom_metric: 1.3821\n",
      "Test res 0.8782658737315727 0.43872166995548373 0.46613995485327314\n",
      "gen_res {10: [(0.8692715561430321, 0.005734626262508919), (0.4304401867577051, 0.016127179698440682), (0.4507800446927586, 0.010719281132486413)]}\n"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60]}\n",
    "lds = [10]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_text_5.h5'\n",
    "f = open('log_text_10.csv', 'a+')\n",
    "f.write('\\nTraining on different % of labeled data\\n')\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2021)\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    f.write('Training on '+str(ld)+' % of labaled data+\\n'+'val_metric,roc_auc,pr_auc,min_rp,savepath\\n')\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "        f.write(str(np.min(his['custom_metric']))+str(rocauc)+str(prauc)+str(minrp)+savepath+'\\n')\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)\n",
    "f.close()\n",
    "\n",
    "# # save to local\n",
    "# log_path = '/content/log.csv'\n",
    "# files.download(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 20\n",
      "Num train: 7492 Num valid: 1873\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_20ld.h5\n",
      "Epoch 1/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4930val_aucs: 0.47959363001637817 0.8778581707707066\n",
      "235/235 [==============================] - 20s 54ms/step - loss: 0.4930 - custom_metric: 1.3575\n",
      "Epoch 2/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4135val_aucs: 0.4825976173885062 0.8806363927086666\n",
      "235/235 [==============================] - 11s 47ms/step - loss: 0.4135 - custom_metric: 1.3632\n",
      "Epoch 3/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3880val_aucs: 0.5057803635790776 0.8829249280460507\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3880 - custom_metric: 1.3887\n",
      "Epoch 4/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3604val_aucs: 0.4850841604389521 0.8822653501758875\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.3604 - custom_metric: 1.3673\n",
      "Epoch 5/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3421val_aucs: 0.47353484237052645 0.8785543918558789\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3421 - custom_metric: 1.3521\n",
      "Epoch 6/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3142val_aucs: 0.5016395968415333 0.8875453043385566\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3142 - custom_metric: 1.3892\n",
      "Epoch 7/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2855val_aucs: 0.48360286016884974 0.8688006342607397\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2855 - custom_metric: 1.3524\n",
      "Epoch 8/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2578val_aucs: 0.47953487677091877 0.8654827577017375\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2578 - custom_metric: 1.3450\n",
      "Epoch 9/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2414val_aucs: 0.48547195970658696 0.8716754610382689\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2414 - custom_metric: 1.3571\n",
      "Epoch 10/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2069val_aucs: 0.4306136061049788 0.8652162615925808\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2069 - custom_metric: 1.2958\n",
      "Epoch 11/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1934val_aucs: 0.4909011093089383 0.8702197260419998\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1934 - custom_metric: 1.3611\n",
      "Epoch 12/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1748val_aucs: 0.47774407346079 0.862061613900437\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1748 - custom_metric: 1.3398\n",
      "Epoch 13/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1684val_aucs: 0.47788423579395783 0.8637538641935827\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1684 - custom_metric: 1.3416\n",
      "Epoch 14/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1405val_aucs: 0.49367179877887724 0.8647798742138365\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1405 - custom_metric: 1.3585\n",
      "Epoch 15/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1137val_aucs: 0.4541529360066706 0.8444995203070035\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1137 - custom_metric: 1.2987\n",
      "Epoch 16/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1236val_aucs: 0.4845298563644658 0.8603493763991046\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1236 - custom_metric: 1.3449\n",
      "Test res 0.8752573637597654 0.44214686114215074 0.4588500563697858\n",
      "Repeat 1 ld 20\n",
      "Num train: 7492 Num valid: 1873\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_20ld.h5\n",
      "Epoch 1/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.5445val_aucs: 0.5208838859375708 0.8853327011221749\n",
      "235/235 [==============================] - 19s 54ms/step - loss: 0.5445 - custom_metric: 1.4062\n",
      "Epoch 2/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4219val_aucs: 0.5247135754103048 0.8888648373774231\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.4219 - custom_metric: 1.4136\n",
      "Epoch 3/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3904val_aucs: 0.5252393893088255 0.8925515904920939\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3904 - custom_metric: 1.4178\n",
      "Epoch 4/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3563val_aucs: 0.5112424916978033 0.8981830801052769\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3563 - custom_metric: 1.4094\n",
      "Epoch 5/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3238val_aucs: 0.4823280640149395 0.874169363871881\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3238 - custom_metric: 1.3565\n",
      "Epoch 6/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3093val_aucs: 0.5143238373407134 0.8826698552099009\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3093 - custom_metric: 1.3970\n",
      "Epoch 7/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2795val_aucs: 0.48075092006332487 0.8860817339078209\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2795 - custom_metric: 1.3668\n",
      "Epoch 8/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2559val_aucs: 0.46326606497814676 0.874186543522928\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2559 - custom_metric: 1.3375\n",
      "Epoch 9/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2233val_aucs: 0.4312306450190841 0.8709739487771525\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2233 - custom_metric: 1.3022\n",
      "Epoch 10/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2263val_aucs: 0.4505697559011393 0.8808591199895548\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2263 - custom_metric: 1.3314\n",
      "Epoch 11/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2092val_aucs: 0.42229312047186235 0.8819757973076051\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2092 - custom_metric: 1.3043\n",
      "Epoch 12/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1830val_aucs: 0.4165703124774688 0.8603053854770102\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1830 - custom_metric: 1.2769\n",
      "Epoch 13/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1423val_aucs: 0.42330173625878353 0.8670535524082433\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1423 - custom_metric: 1.2904\n",
      "Test res 0.8833448033641204 0.4825294518294377 0.4863636363636364\n",
      "Repeat 2 ld 20\n",
      "Num train: 7492 Num valid: 1873\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_20ld.h5\n",
      "Epoch 1/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.5051val_aucs: 0.49405227739697216 0.8894463063817903\n",
      "235/235 [==============================] - 21s 55ms/step - loss: 0.5051 - custom_metric: 1.3835\n",
      "Epoch 2/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4156val_aucs: 0.4853347227397523 0.8872852953498115\n",
      "235/235 [==============================] - 11s 47ms/step - loss: 0.4156 - custom_metric: 1.3726\n",
      "Epoch 3/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3739val_aucs: 0.4829777733484752 0.8959677419354839\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3739 - custom_metric: 1.3789\n",
      "Epoch 4/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3486val_aucs: 0.44445888419594465 0.8746718335428012\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3486 - custom_metric: 1.3191\n",
      "Epoch 5/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3138val_aucs: 0.4403878100308651 0.8674870828096636\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3138 - custom_metric: 1.3079\n",
      "Epoch 6/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2849val_aucs: 0.437826891457582 0.8694351347577154\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2849 - custom_metric: 1.3073\n",
      "Epoch 7/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2775val_aucs: 0.4676587996320051 0.8701927105152911\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2775 - custom_metric: 1.3379\n",
      "Epoch 8/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2407val_aucs: 0.4458445880355717 0.87073732718894\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2407 - custom_metric: 1.3166\n",
      "Epoch 9/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2102val_aucs: 0.4196885337525159 0.8470918866080157\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2102 - custom_metric: 1.2668\n",
      "Epoch 10/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1826val_aucs: 0.42237437138233863 0.8445712889261275\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1826 - custom_metric: 1.2669\n",
      "Epoch 11/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1818val_aucs: 0.38828364071277255 0.8534143276078759\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1818 - custom_metric: 1.2417\n",
      "Test res 0.8780648713299857 0.45500848590412324 0.475\n",
      "Repeat 3 ld 20\n",
      "Num train: 7492 Num valid: 1873\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_20ld.h5\n",
      "Epoch 1/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.5047val_aucs: 0.45958534234835696 0.8913924676955869\n",
      "235/235 [==============================] - 19s 55ms/step - loss: 0.5047 - custom_metric: 1.3510\n",
      "Epoch 2/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4237val_aucs: 0.4886231252097404 0.8960486167938543\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.4237 - custom_metric: 1.3847\n",
      "Epoch 3/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3784val_aucs: 0.4855845421466387 0.8877227371051948\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.3784 - custom_metric: 1.3733\n",
      "Epoch 4/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3611val_aucs: 0.4685638420685798 0.8811635297923763\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.3611 - custom_metric: 1.3497\n",
      "Epoch 5/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3413val_aucs: 0.5202821133907864 0.8922615309468984\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3413 - custom_metric: 1.4125\n",
      "Epoch 6/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2950val_aucs: 0.48135181777556757 0.8667668943992997\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2950 - custom_metric: 1.3481\n",
      "Epoch 7/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2703val_aucs: 0.491882725673961 0.8818264284037782\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2703 - custom_metric: 1.3737\n",
      "Epoch 8/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2505val_aucs: 0.47987080829033685 0.8672521742440101\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2505 - custom_metric: 1.3471\n",
      "Epoch 9/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2261val_aucs: 0.4802684205359639 0.8785436529836781\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2261 - custom_metric: 1.3588\n",
      "Epoch 10/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2062val_aucs: 0.4701083354510325 0.871626036373786\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2062 - custom_metric: 1.3417\n",
      "Epoch 11/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1865val_aucs: 0.46943679964093415 0.8724855843340247\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1865 - custom_metric: 1.3419\n",
      "Epoch 12/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1761val_aucs: 0.43907790287938514 0.8553707474578314\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1761 - custom_metric: 1.2944\n",
      "Epoch 13/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1507val_aucs: 0.45393987757770815 0.8605629246198641\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1507 - custom_metric: 1.3145\n",
      "Epoch 14/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1221val_aucs: 0.48178522042818633 0.8645434880519662\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1221 - custom_metric: 1.3463\n",
      "Epoch 15/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1281val_aucs: 0.43733653288036156 0.8571437633610545\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1281 - custom_metric: 1.2945\n",
      "Test res 0.867211097610753 0.42951627566745376 0.4465691788526434\n",
      "Repeat 4 ld 20\n",
      "Num train: 7492 Num valid: 1873\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_20ld.h5\n",
      "Epoch 1/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4696val_aucs: 0.45180939595588604 0.879861456365384\n",
      "235/235 [==============================] - 20s 54ms/step - loss: 0.4696 - custom_metric: 1.3317\n",
      "Epoch 2/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4173val_aucs: 0.43922611297051817 0.8744390308574459\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.4173 - custom_metric: 1.3137\n",
      "Epoch 3/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3767val_aucs: 0.42964502631706103 0.8712041364223924\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.3767 - custom_metric: 1.3008\n",
      "Epoch 4/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3540val_aucs: 0.4457007704342208 0.8813927281164031\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3540 - custom_metric: 1.3271\n",
      "Epoch 5/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3339val_aucs: 0.44256888226559016 0.8730071923370124\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.3339 - custom_metric: 1.3156\n",
      "Epoch 6/1000\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.2982val_aucs: 0.4436932885278364 0.8636538397799213\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2981 - custom_metric: 1.3073\n",
      "Epoch 7/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2638val_aucs: 0.4330650352593085 0.8708428623512643\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2638 - custom_metric: 1.3039\n",
      "Epoch 8/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2416val_aucs: 0.4560001668799263 0.8748433926618275\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2416 - custom_metric: 1.3308\n",
      "Epoch 9/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2302val_aucs: 0.4261112580979363 0.8748964237181399\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2302 - custom_metric: 1.3010\n",
      "Epoch 10/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1927val_aucs: 0.4313236204330991 0.8397666633522258\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1927 - custom_metric: 1.2711\n",
      "Epoch 11/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1711val_aucs: 0.448618857717637 0.8496967286467136\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1711 - custom_metric: 1.2983\n",
      "Test res 0.8764429694248531 0.45834011129039254 0.4625\n",
      "Repeat 5 ld 20\n",
      "Num train: 7492 Num valid: 1873\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_20ld.h5\n",
      "Epoch 1/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4804val_aucs: 0.45380291100310766 0.8687440038375439\n",
      "235/235 [==============================] - 19s 55ms/step - loss: 0.4804 - custom_metric: 1.3225\n",
      "Epoch 2/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3961val_aucs: 0.4409877480168994 0.8644400916746616\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.3961 - custom_metric: 1.3054\n",
      "Epoch 3/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3648val_aucs: 0.4644856011640997 0.8757661763138258\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3648 - custom_metric: 1.3403\n",
      "Epoch 4/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3393val_aucs: 0.4496759594730381 0.8580641722630851\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3393 - custom_metric: 1.3077\n",
      "Epoch 5/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3160val_aucs: 0.46057634035562284 0.8563452723590236\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3160 - custom_metric: 1.3169\n",
      "Epoch 6/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2841val_aucs: 0.45419723203469714 0.8515749920051167\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2841 - custom_metric: 1.3058\n",
      "Epoch 7/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2739val_aucs: 0.4390202273070873 0.8534537895746721\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2739 - custom_metric: 1.2925\n",
      "Epoch 8/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2261val_aucs: 0.44242841872414945 0.8439065664641296\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2261 - custom_metric: 1.2863\n",
      "Epoch 9/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2122val_aucs: 0.39779989477904365 0.8278734942969832\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2122 - custom_metric: 1.2257\n",
      "Epoch 10/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1774val_aucs: 0.43800698675369787 0.8480705681697047\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1774 - custom_metric: 1.2861\n",
      "Epoch 11/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1578val_aucs: 0.38695228994736297 0.8301520360302739\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1578 - custom_metric: 1.2171\n",
      "Epoch 12/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2159val_aucs: 0.4146977386028274 0.8384100842127704\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2159 - custom_metric: 1.2531\n",
      "Epoch 13/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1524val_aucs: 0.40622729101042226 0.8344692729986142\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1524 - custom_metric: 1.2407\n",
      "Test res 0.8738778750225445 0.44211764230922634 0.4590909090909091\n",
      "Repeat 6 ld 20\n",
      "Num train: 7492 Num valid: 1873\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_20ld.h5\n",
      "Epoch 1/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.5047val_aucs: 0.4019138856622739 0.860885929357267\n",
      "235/235 [==============================] - 19s 54ms/step - loss: 0.5047 - custom_metric: 1.2628\n",
      "Epoch 2/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4125val_aucs: 0.4132959310588378 0.8613164966668151\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.4125 - custom_metric: 1.2746\n",
      "Epoch 3/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3758val_aucs: 0.3964171840185326 0.8519999109171086\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3758 - custom_metric: 1.2484\n",
      "Epoch 4/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3626val_aucs: 0.39620855454406295 0.859575668492866\n",
      "235/235 [==============================] - 11s 49ms/step - loss: 0.3626 - custom_metric: 1.2558\n",
      "Epoch 5/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3278val_aucs: 0.36504461998705856 0.8506933618398587\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3278 - custom_metric: 1.2157\n",
      "Epoch 6/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2975val_aucs: 0.38850361889643076 0.8505189078437485\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2975 - custom_metric: 1.2390\n",
      "Epoch 7/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2847val_aucs: 0.3956536622084064 0.855604056240999\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2847 - custom_metric: 1.2513\n",
      "Epoch 8/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2735val_aucs: 0.33675225438811063 0.8426721898059477\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2735 - custom_metric: 1.1794\n",
      "Epoch 9/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2398val_aucs: 0.37141036684901313 0.8545239261799773\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2398 - custom_metric: 1.2259\n",
      "Epoch 10/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2209val_aucs: 0.3436286983902559 0.8427427137618221\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2209 - custom_metric: 1.1864\n",
      "Epoch 11/1000\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.1787val_aucs: 0.3462449436630676 0.8414138939616647\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1786 - custom_metric: 1.1877\n",
      "Epoch 12/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1671val_aucs: 0.31415980065096694 0.839558000386026\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1671 - custom_metric: 1.1537\n",
      "Test res 0.8800550798788765 0.4644928157668162 0.4693181818181818\n",
      "Repeat 7 ld 20\n",
      "Num train: 7492 Num valid: 1873\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_20ld.h5\n",
      "Epoch 1/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4895val_aucs: 0.44199832042338105 0.878878429655575\n",
      "235/235 [==============================] - 19s 54ms/step - loss: 0.4895 - custom_metric: 1.3209\n",
      "Epoch 2/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4248val_aucs: 0.4502389797401409 0.8831910391126678\n",
      "235/235 [==============================] - 11s 47ms/step - loss: 0.4248 - custom_metric: 1.3334\n",
      "Epoch 3/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3941val_aucs: 0.47558035258843273 0.8889886164623467\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3941 - custom_metric: 1.3646\n",
      "Epoch 4/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3749val_aucs: 0.4636119099596223 0.8822971395213076\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3749 - custom_metric: 1.3459\n",
      "Epoch 5/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3430val_aucs: 0.4230313297713731 0.8726430239346177\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3430 - custom_metric: 1.2957\n",
      "Epoch 6/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3167val_aucs: 0.42466971295580674 0.8762587565674256\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3167 - custom_metric: 1.3009\n",
      "Epoch 7/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2989val_aucs: 0.442370763306947 0.8867301517805022\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2989 - custom_metric: 1.3291\n",
      "Epoch 8/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2714val_aucs: 0.42437757063556686 0.8710413018096905\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2714 - custom_metric: 1.2954\n",
      "Epoch 9/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2320val_aucs: 0.3954225635775457 0.8712346760070051\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2320 - custom_metric: 1.2667\n",
      "Epoch 10/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2142val_aucs: 0.3924360308506092 0.8644556333917105\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2142 - custom_metric: 1.2569\n",
      "Epoch 11/1000\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.2094val_aucs: 0.4130676259325571 0.8723073555166374\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2093 - custom_metric: 1.2854\n",
      "Epoch 12/1000\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.1979val_aucs: 0.37875773850713845 0.8564032399299474\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1988 - custom_metric: 1.2352\n",
      "Epoch 13/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1787val_aucs: 0.3978149240204496 0.8647985989492118\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1787 - custom_metric: 1.2626\n",
      "Test res 0.8866301365962012 0.4696587802634784 0.46298342541436466\n",
      "Repeat 8 ld 20\n",
      "Num train: 7492 Num valid: 1873\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_20ld.h5\n",
      "Epoch 1/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4980val_aucs: 0.5059386999595462 0.8904875542739716\n",
      "235/235 [==============================] - 19s 54ms/step - loss: 0.4980 - custom_metric: 1.3964\n",
      "Epoch 2/1000\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.4195val_aucs: 0.485719461531311 0.8890855457227139\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.4193 - custom_metric: 1.3748\n",
      "Epoch 3/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3755val_aucs: 0.4665166774011767 0.8919028205893076\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3755 - custom_metric: 1.3584\n",
      "Epoch 4/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3579val_aucs: 0.4975344389089943 0.8889330814358158\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3579 - custom_metric: 1.3865\n",
      "Epoch 5/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3272val_aucs: 0.45932851500284005 0.8827715355805243\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3272 - custom_metric: 1.3421\n",
      "Epoch 6/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3172val_aucs: 0.4602951414716468 0.8802890192569022\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.3172 - custom_metric: 1.3406\n",
      "Epoch 7/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2802val_aucs: 0.4901879631286917 0.887358721951543\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2802 - custom_metric: 1.3775\n",
      "Epoch 8/1000\n",
      "234/235 [============================>.] - ETA: 0s - loss: 0.2616val_aucs: 0.43090372985899933 0.8579530012263432\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2617 - custom_metric: 1.2889\n",
      "Epoch 9/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2607val_aucs: 0.45309175022335635 0.8715455238474031\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2607 - custom_metric: 1.3246\n",
      "Epoch 10/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2165val_aucs: 0.46061538248227 0.8685326969606576\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2165 - custom_metric: 1.3291\n",
      "Epoch 11/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1982val_aucs: 0.4465611472779032 0.8528785920254549\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1982 - custom_metric: 1.2994\n",
      "Test res 0.8726672330488766 0.44949356170138643 0.4583333333333333\n",
      "Repeat 9 ld 20\n",
      "Num train: 7492 Num valid: 1873\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_20ld.h5\n",
      "Epoch 1/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4798val_aucs: 0.4689857913959638 0.8862531577107503\n",
      "235/235 [==============================] - 20s 53ms/step - loss: 0.4798 - custom_metric: 1.3552\n",
      "Epoch 2/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.4039val_aucs: 0.5091949555557186 0.9002855955623857\n",
      "235/235 [==============================] - 11s 47ms/step - loss: 0.4039 - custom_metric: 1.4095\n",
      "Epoch 3/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3675val_aucs: 0.4983000380355055 0.8970602784721626\n",
      "235/235 [==============================] - 11s 47ms/step - loss: 0.3675 - custom_metric: 1.3954\n",
      "Epoch 4/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3440val_aucs: 0.5193172169957717 0.8940064506341805\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.3440 - custom_metric: 1.4133\n",
      "Epoch 5/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.3232val_aucs: 0.5211371063308876 0.8944318758945472\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.3232 - custom_metric: 1.4156\n",
      "Epoch 6/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2900val_aucs: 0.5210208617154991 0.8844986907455166\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2900 - custom_metric: 1.4055\n",
      "Epoch 7/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2742val_aucs: 0.48267135982668624 0.886028902534743\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2742 - custom_metric: 1.3687\n",
      "Epoch 8/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2480val_aucs: 0.5065141233611178 0.8769762487385646\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.2480 - custom_metric: 1.3835\n",
      "Epoch 9/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2426val_aucs: 0.5026400830817677 0.8757692282324077\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.2426 - custom_metric: 1.3784\n",
      "Epoch 10/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1962val_aucs: 0.5060384232958115 0.885692519770732\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1962 - custom_metric: 1.3917\n",
      "Epoch 11/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1908val_aucs: 0.49299164905505216 0.8744731652298947\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1908 - custom_metric: 1.3675\n",
      "Epoch 12/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1737val_aucs: 0.48373710025105743 0.8760561429428875\n",
      "235/235 [==============================] - 11s 45ms/step - loss: 0.1737 - custom_metric: 1.3598\n",
      "Epoch 13/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1450val_aucs: 0.5055560067389483 0.8726032728064217\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1450 - custom_metric: 1.3782\n",
      "Epoch 14/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1717val_aucs: 0.467881520829291 0.870334338084465\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1717 - custom_metric: 1.3382\n",
      "Epoch 15/1000\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.1216val_aucs: 0.44268617677189337 0.8588280688331476\n",
      "235/235 [==============================] - 11s 46ms/step - loss: 0.1216 - custom_metric: 1.3015\n",
      "Test res 0.878683659715037 0.45440619074798383 0.46311010215664017\n",
      "gen_res {20: [(0.8772235089751014, 0.00522961642918818), (0.4547710176622449, 0.014438657107055853), (0.4642118823399494, 0.010196114063634722)]}\n"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60]}\n",
    "lds = [20]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_text_5.h5'\n",
    "f = open('log_text_20.csv', 'a+')\n",
    "f.write('\\nTraining on different % of labeled data\\n')\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2021)\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    f.write('Training on '+str(ld)+' % of labaled data+\\n'+'val_metric,roc_auc,pr_auc,min_rp,savepath\\n')\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "        f.write(str(np.min(his['custom_metric']))+str(rocauc)+str(prauc)+str(minrp)+savepath+'\\n')\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)\n",
    "f.close()\n",
    "\n",
    "# # save to local\n",
    "# log_path = '/content/log.csv'\n",
    "# files.download(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 30\n",
      "Num train: 11238 Num valid: 2809\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_30ld.h5\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4821val_aucs: 0.5181958311146816 0.8943900557731101\n",
      "352/352 [==============================] - 25s 52ms/step - loss: 0.4821 - custom_metric: 1.4126\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4062val_aucs: 0.556806050781298 0.9008573632372137\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.4062 - custom_metric: 1.4577\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3799val_aucs: 0.5316854655829979 0.8956182508603299\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3799 - custom_metric: 1.4273\n",
      "Epoch 4/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3571val_aucs: 0.5318692054304193 0.8942357897235077\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.3571 - custom_metric: 1.4261\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3399val_aucs: 0.534781233351795 0.8910421858312567\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.3399 - custom_metric: 1.4258\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3176val_aucs: 0.511284426341885 0.8825086032989202\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3176 - custom_metric: 1.3938\n",
      "Epoch 7/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2924val_aucs: 0.5090164491531549 0.887184051263795\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2924 - custom_metric: 1.3962\n",
      "Epoch 8/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2714val_aucs: 0.4902156829282974 0.8789634508128634\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2714 - custom_metric: 1.3692\n",
      "Epoch 9/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2558val_aucs: 0.5063322410126311 0.8813219413789012\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2558 - custom_metric: 1.3877\n",
      "Epoch 10/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2373val_aucs: 0.4451595322283129 0.8767251097662276\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2375 - custom_metric: 1.3219\n",
      "Epoch 11/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2150val_aucs: 0.4298014560970056 0.8674632134804795\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2150 - custom_metric: 1.2973\n",
      "Epoch 12/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1946val_aucs: 0.4475770445214312 0.8661801352794588\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1946 - custom_metric: 1.3138\n",
      "Test res 0.8888326791460601 0.469709409982859 0.4688195991091314\n",
      "Repeat 1 ld 30\n",
      "Num train: 11238 Num valid: 2809\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_30ld.h5\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4797val_aucs: 0.4910903005433929 0.8935423279516804\n",
      "352/352 [==============================] - 25s 51ms/step - loss: 0.4797 - custom_metric: 1.3846\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4120val_aucs: 0.500514164435337 0.8937603767883899\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.4120 - custom_metric: 1.3943\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3804val_aucs: 0.5072364312212354 0.8875117201249733\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3804 - custom_metric: 1.3947\n",
      "Epoch 4/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3620val_aucs: 0.4791899926984709 0.8883932604219558\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3620 - custom_metric: 1.3676\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3375val_aucs: 0.47550254355365645 0.8850867055624259\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3375 - custom_metric: 1.3606\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3112val_aucs: 0.43193798554601115 0.8788022265901211\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3112 - custom_metric: 1.3107\n",
      "Epoch 7/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2928val_aucs: 0.45865064605151074 0.8800653523513451\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2928 - custom_metric: 1.3387\n",
      "Epoch 8/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2640val_aucs: 0.44221195527649143 0.8695538409302587\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2640 - custom_metric: 1.3118\n",
      "Epoch 9/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2418val_aucs: 0.416394837317298 0.8570284927529911\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2418 - custom_metric: 1.2734\n",
      "Epoch 10/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2213val_aucs: 0.39917935074408323 0.8588211656890811\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2213 - custom_metric: 1.2580\n",
      "Epoch 11/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1915val_aucs: 0.41606211728150044 0.8660074323503484\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1915 - custom_metric: 1.2821\n",
      "Epoch 12/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1998val_aucs: 0.38062108857414856 0.8469904588059023\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1998 - custom_metric: 1.2276\n",
      "Epoch 13/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1670val_aucs: 0.4027021920587423 0.8622523198838735\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1670 - custom_metric: 1.2650\n",
      "Test res 0.8855044519540186 0.45937393940849264 0.4604966139954853\n",
      "Repeat 2 ld 30\n",
      "Num train: 11238 Num valid: 2809\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_30ld.h5\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4766val_aucs: 0.49315599383186975 0.9012680835863547\n",
      "352/352 [==============================] - 25s 51ms/step - loss: 0.4766 - custom_metric: 1.3944\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4056val_aucs: 0.5001272177235551 0.9010745966541643\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.4056 - custom_metric: 1.4012\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3816val_aucs: 0.4944319443586844 0.8964606775019348\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3816 - custom_metric: 1.3909\n",
      "Epoch 4/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3636val_aucs: 0.4954680046162321 0.8911278799785676\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.3636 - custom_metric: 1.3866\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3375val_aucs: 0.4987174076922349 0.8917991307971662\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3375 - custom_metric: 1.3905\n",
      "Epoch 6/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.3213val_aucs: 0.5081462188463641 0.8983479192712983\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3214 - custom_metric: 1.4065\n",
      "Epoch 7/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2986val_aucs: 0.490127837011994 0.8810516758945051\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2986 - custom_metric: 1.3712\n",
      "Epoch 8/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2747val_aucs: 0.5047859002410611 0.8873429779127224\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2747 - custom_metric: 1.3921\n",
      "Epoch 9/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2587val_aucs: 0.46825159244694986 0.8740504256712507\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2590 - custom_metric: 1.3423\n",
      "Epoch 10/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2326val_aucs: 0.46965263646535654 0.874421027564446\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2326 - custom_metric: 1.3441\n",
      "Epoch 11/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2120val_aucs: 0.47085089489979043 0.870125617669822\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2120 - custom_metric: 1.3410\n",
      "Epoch 12/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1998val_aucs: 0.4456337094821051 0.8790781091861641\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1998 - custom_metric: 1.3247\n",
      "Epoch 13/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1868val_aucs: 0.4580726132325596 0.860120854914568\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1868 - custom_metric: 1.3182\n",
      "Epoch 14/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1796val_aucs: 0.4626593131135319 0.8732109900577486\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1795 - custom_metric: 1.3359\n",
      "Epoch 15/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1670val_aucs: 0.467791743395901 0.8705795677799607\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1672 - custom_metric: 1.3384\n",
      "Epoch 16/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1479val_aucs: 0.43892917095036305 0.8681014466869084\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1479 - custom_metric: 1.3070\n",
      "Test res 0.8788229612613552 0.47912166255673816 0.48645598194130923\n",
      "Repeat 3 ld 30\n",
      "Num train: 11238 Num valid: 2809\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_30ld.h5\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4807val_aucs: 0.4741084889328828 0.8839659318579001\n",
      "352/352 [==============================] - 25s 51ms/step - loss: 0.4807 - custom_metric: 1.3581\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4150val_aucs: 0.5030789826640133 0.8955332815739504\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.4150 - custom_metric: 1.3986\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3813val_aucs: 0.47887577938727244 0.8913009342859385\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3813 - custom_metric: 1.3702\n",
      "Epoch 4/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.3549val_aucs: 0.4977982321235646 0.8974248253120829\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3548 - custom_metric: 1.3952\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3292val_aucs: 0.47441540897231327 0.8859316252736995\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3292 - custom_metric: 1.3603\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3191val_aucs: 0.4654567602472715 0.8844878874320659\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3191 - custom_metric: 1.3499\n",
      "Epoch 7/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2913val_aucs: 0.48202133408866094 0.8906219558649487\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2913 - custom_metric: 1.3726\n",
      "Epoch 8/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2663val_aucs: 0.42841607875816545 0.8706800543182737\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2663 - custom_metric: 1.2991\n",
      "Epoch 9/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2463val_aucs: 0.45845989564331796 0.8766890860397966\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2463 - custom_metric: 1.3351\n",
      "Epoch 10/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2286val_aucs: 0.45035050213681016 0.8760595407372512\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2286 - custom_metric: 1.3264\n",
      "Epoch 11/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2021val_aucs: 0.4168896122163265 0.8734192306462071\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2020 - custom_metric: 1.2903\n",
      "Epoch 12/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2037val_aucs: 0.4503897362654136 0.8759425005597574\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2037 - custom_metric: 1.3263\n",
      "Test res 0.8845590050025155 0.46996837830465904 0.4772727272727273\n",
      "Repeat 4 ld 30\n",
      "Num train: 11238 Num valid: 2809\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_30ld.h5\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4619val_aucs: 0.43123549100074193 0.8724306754006693\n",
      "352/352 [==============================] - 25s 51ms/step - loss: 0.4619 - custom_metric: 1.3037\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4038val_aucs: 0.46030096957502287 0.8782651994531969\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.4038 - custom_metric: 1.3386\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3729val_aucs: 0.46661418631796997 0.8800435463019664\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.3729 - custom_metric: 1.3467\n",
      "Epoch 4/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3494val_aucs: 0.42952070735863696 0.8698327426129019\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3494 - custom_metric: 1.2994\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3264val_aucs: 0.43155152114631823 0.871829130249216\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3264 - custom_metric: 1.3034\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3071val_aucs: 0.4313620756562756 0.8672456345450834\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.3071 - custom_metric: 1.2986\n",
      "Epoch 7/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2813val_aucs: 0.38166026554330024 0.8617466768109756\n",
      "352/352 [==============================] - 18s 52ms/step - loss: 0.2813 - custom_metric: 1.2434\n",
      "Epoch 8/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2679val_aucs: 0.42713739977879717 0.8666595532792717\n",
      "352/352 [==============================] - 19s 54ms/step - loss: 0.2679 - custom_metric: 1.2938\n",
      "Epoch 9/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2376val_aucs: 0.4323936535178324 0.8648611033791682\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2376 - custom_metric: 1.2973\n",
      "Epoch 10/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2145val_aucs: 0.41533049186782484 0.8555935967142336\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2145 - custom_metric: 1.2709\n",
      "Epoch 11/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2007val_aucs: 0.4237161113222609 0.8600270927276439\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2007 - custom_metric: 1.2837\n",
      "Epoch 12/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1784val_aucs: 0.4403589121497466 0.8608513178323344\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1784 - custom_metric: 1.3012\n",
      "Epoch 13/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1616val_aucs: 0.4380938564030241 0.858757507716479\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1616 - custom_metric: 1.2969\n",
      "Test res 0.8788030271388838 0.46595127304913897 0.4727272727272727\n",
      "Repeat 5 ld 30\n",
      "Num train: 11238 Num valid: 2809\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_30ld.h5\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4759val_aucs: 0.44555379636209885 0.8801556868694106\n",
      "352/352 [==============================] - 25s 51ms/step - loss: 0.4759 - custom_metric: 1.3257\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4046val_aucs: 0.43221029212655826 0.8795918748773475\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.4046 - custom_metric: 1.3118\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3775val_aucs: 0.4693558018562532 0.8849060365262952\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3775 - custom_metric: 1.3543\n",
      "Epoch 4/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3507val_aucs: 0.433606223804516 0.8774892610947921\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3507 - custom_metric: 1.3111\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3228val_aucs: 0.41005244219419246 0.874905382379785\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3228 - custom_metric: 1.2850\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3071val_aucs: 0.43851250142434195 0.880224216503805\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3071 - custom_metric: 1.3187\n",
      "Epoch 7/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2806val_aucs: 0.4301849142523222 0.8676194362503077\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2805 - custom_metric: 1.2978\n",
      "Epoch 8/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2535val_aucs: 0.43065933357846686 0.8660121048254208\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2535 - custom_metric: 1.2967\n",
      "Epoch 9/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2400val_aucs: 0.43633325319175514 0.8707873743493578\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2400 - custom_metric: 1.3071\n",
      "Epoch 10/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2216val_aucs: 0.4105317268302155 0.8644047734005338\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2216 - custom_metric: 1.2749\n",
      "Epoch 11/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1838val_aucs: 0.41919373287432 0.8576623918711394\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.1838 - custom_metric: 1.2769\n",
      "Epoch 12/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1825val_aucs: 0.4073176861421716 0.8613972569456342\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1825 - custom_metric: 1.2687\n",
      "Epoch 13/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1813val_aucs: 0.3691818894158403 0.8461244934258276\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1813 - custom_metric: 1.2153\n",
      "Test res 0.8829062526697484 0.46600317707346117 0.475\n",
      "Repeat 6 ld 30\n",
      "Num train: 11238 Num valid: 2809\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_30ld.h5\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4806val_aucs: 0.3952917172779454 0.8598502334979192\n",
      "352/352 [==============================] - 27s 58ms/step - loss: 0.4806 - custom_metric: 1.2551\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4212val_aucs: 0.4017575115892262 0.8633961904379591\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.4212 - custom_metric: 1.2652\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3871val_aucs: 0.41132375123677745 0.8628174635034053\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3871 - custom_metric: 1.2741\n",
      "Epoch 4/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3612val_aucs: 0.4251691433682563 0.8579802429984076\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.3612 - custom_metric: 1.2831\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3485val_aucs: 0.405643219206859 0.8547286673892391\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3485 - custom_metric: 1.2604\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3187val_aucs: 0.37153219070328 0.8508465135883746\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3187 - custom_metric: 1.2224\n",
      "Epoch 7/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2913val_aucs: 0.36027699557890963 0.8429935570631447\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2913 - custom_metric: 1.2033\n",
      "Epoch 8/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2640val_aucs: 0.3844221022828496 0.8425503124456397\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.2640 - custom_metric: 1.2270\n",
      "Epoch 9/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2356val_aucs: 0.35779053070219324 0.840422738281616\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2356 - custom_metric: 1.1982\n",
      "Epoch 10/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2320val_aucs: 0.36116284085329303 0.8420267820106245\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2320 - custom_metric: 1.2032\n",
      "Epoch 11/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2016val_aucs: 0.35595196012876884 0.8309180683232307\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2016 - custom_metric: 1.1869\n",
      "Epoch 12/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1825val_aucs: 0.3182496022714035 0.818340793223877\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1825 - custom_metric: 1.1366\n",
      "Epoch 13/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1775val_aucs: 0.3347025223294361 0.8398055410595051\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1775 - custom_metric: 1.1745\n",
      "Epoch 14/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1529val_aucs: 0.3453053889802899 0.8445440769138133\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1529 - custom_metric: 1.1898\n",
      "Test res 0.8783031315557159 0.4646051806657301 0.475\n",
      "Repeat 7 ld 30\n",
      "Num train: 11238 Num valid: 2809\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_30ld.h5\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4772val_aucs: 0.44799002609595273 0.8774347389558232\n",
      "352/352 [==============================] - 24s 51ms/step - loss: 0.4772 - custom_metric: 1.3254\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4011val_aucs: 0.45574211095913 0.8785281752008033\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.4011 - custom_metric: 1.3343\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3796val_aucs: 0.4599961543799471 0.8806083709839357\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3796 - custom_metric: 1.3406\n",
      "Epoch 4/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.3649val_aucs: 0.4439349704866354 0.8781516691767068\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3649 - custom_metric: 1.3221\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3416val_aucs: 0.41311238142962564 0.8749215612449798\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3416 - custom_metric: 1.2880\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3200val_aucs: 0.42149701498633296 0.8755380898594377\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3200 - custom_metric: 1.2970\n",
      "Epoch 7/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.3005val_aucs: 0.4001466645020245 0.8745215235943775\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3004 - custom_metric: 1.2747\n",
      "Epoch 8/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2697val_aucs: 0.387621680265421 0.8582580321285141\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2696 - custom_metric: 1.2459\n",
      "Epoch 9/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2588val_aucs: 0.39785938671528337 0.8681005271084338\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.2588 - custom_metric: 1.2660\n",
      "Epoch 10/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2422val_aucs: 0.426321060719459 0.8648249246987951\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2422 - custom_metric: 1.2911\n",
      "Epoch 11/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2126val_aucs: 0.40754967209585563 0.8666086219879517\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2126 - custom_metric: 1.2742\n",
      "Epoch 12/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1985val_aucs: 0.42171850277729594 0.8697555848393574\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1984 - custom_metric: 1.2915\n",
      "Epoch 13/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1803val_aucs: 0.40678075532092556 0.8677930471887552\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1803 - custom_metric: 1.2746\n",
      "Test res 0.888590087994912 0.47610938780363976 0.4784090909090909\n",
      "Repeat 8 ld 30\n",
      "Num train: 11238 Num valid: 2809\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_30ld.h5\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4870val_aucs: 0.43505910600743497 0.8820992575224698\n",
      "352/352 [==============================] - 25s 51ms/step - loss: 0.4870 - custom_metric: 1.3172\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4140val_aucs: 0.4667101454191904 0.8879093395857757\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.4140 - custom_metric: 1.3546\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3797val_aucs: 0.48149185654867355 0.8865072293864791\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3797 - custom_metric: 1.3680\n",
      "Epoch 4/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3617val_aucs: 0.4600533265136966 0.8851613911684251\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.3617 - custom_metric: 1.3452\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3384val_aucs: 0.48228731889088966 0.8891660805001953\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3384 - custom_metric: 1.3715\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3231val_aucs: 0.46698168443094595 0.8804454865181712\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3231 - custom_metric: 1.3474\n",
      "Epoch 7/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2995val_aucs: 0.45653568681572165 0.8876389214536928\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2995 - custom_metric: 1.3442\n",
      "Epoch 8/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2717val_aucs: 0.4688807532460103 0.8874544744040641\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2717 - custom_metric: 1.3563\n",
      "Epoch 9/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2546val_aucs: 0.41396292753890046 0.8725486518171162\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2546 - custom_metric: 1.2865\n",
      "Epoch 10/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.2425val_aucs: 0.44602710795754674 0.870399374755764\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2425 - custom_metric: 1.3164\n",
      "Epoch 11/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2076val_aucs: 0.4339962118984092 0.870571316920672\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2076 - custom_metric: 1.3046\n",
      "Epoch 12/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2055val_aucs: 0.4372089484186642 0.8747620164126613\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2055 - custom_metric: 1.3120\n",
      "Epoch 13/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1960val_aucs: 0.45101985207657747 0.8656240719030872\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1960 - custom_metric: 1.3166\n",
      "Epoch 14/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1781val_aucs: 0.40247341552559546 0.8623462289957012\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1780 - custom_metric: 1.2648\n",
      "Epoch 15/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1743val_aucs: 0.4225277517042164 0.8621227041813208\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1743 - custom_metric: 1.2847\n",
      "Test res 0.8848453207020608 0.46815340777970993 0.4772727272727273\n",
      "Repeat 9 ld 30\n",
      "Num train: 11238 Num valid: 2809\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_30ld.h5\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.4719val_aucs: 0.478719530448921 0.8956151077303939\n",
      "352/352 [==============================] - 25s 52ms/step - loss: 0.4719 - custom_metric: 1.3743\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3997val_aucs: 0.497675518418236 0.8977587762282824\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3997 - custom_metric: 1.3954\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3744val_aucs: 0.5011945268610204 0.8922066673260264\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3744 - custom_metric: 1.3934\n",
      "Epoch 4/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3638val_aucs: 0.5135883786015427 0.8984675879720792\n",
      "352/352 [==============================] - 16s 46ms/step - loss: 0.3638 - custom_metric: 1.4121\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3430val_aucs: 0.5094140298152612 0.8935358766637596\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3430 - custom_metric: 1.4029\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.3078val_aucs: 0.5017568135398508 0.8902165996817091\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.3078 - custom_metric: 1.3920\n",
      "Epoch 7/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2947val_aucs: 0.49206969570946785 0.8882954651033846\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2947 - custom_metric: 1.3804\n",
      "Epoch 8/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2681val_aucs: 0.48876837256632216 0.8751217567741723\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2681 - custom_metric: 1.3639\n",
      "Epoch 9/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2503val_aucs: 0.46950205498274505 0.8700746575075601\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2503 - custom_metric: 1.3396\n",
      "Epoch 10/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.2245val_aucs: 0.4555483926225342 0.8687289641757853\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.2245 - custom_metric: 1.3243\n",
      "Epoch 11/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1955val_aucs: 0.4732015037136649 0.8624875246136001\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1955 - custom_metric: 1.3357\n",
      "Epoch 12/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1734val_aucs: 0.46546898591320696 0.8539697953287356\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1734 - custom_metric: 1.3194\n",
      "Epoch 13/1000\n",
      "351/352 [============================>.] - ETA: 0s - loss: 0.1608val_aucs: 0.45395164472699623 0.8627287903445754\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1607 - custom_metric: 1.3167\n",
      "Epoch 14/1000\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.1809val_aucs: 0.4512154651978365 0.8606518070953105\n",
      "352/352 [==============================] - 16s 45ms/step - loss: 0.1809 - custom_metric: 1.3119\n",
      "Test res 0.8849222094601649 0.475592950465417 0.48306997742663654\n",
      "gen_res {30: [(0.8836089126885435, 0.003667368983958862), (0.46945887670898456, 0.005716307076883842), (0.4754523990654381, 0.00685551411729841)]}\n"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60]}\n",
    "lds = [30]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_text_5.h5'\n",
    "f = open('log_text_30.csv', 'a+')\n",
    "f.write('\\nTraining on different % of labeled data\\n')\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2021)\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    f.write('Training on '+str(ld)+' % of labaled data+\\n'+'val_metric,roc_auc,pr_auc,min_rp,savepath\\n')\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "        f.write(str(np.min(his['custom_metric']))+str(rocauc)+str(prauc)+str(minrp)+savepath+'\\n')\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)\n",
    "f.close()\n",
    "\n",
    "# # save to local\n",
    "# log_path = '/content/log.csv'\n",
    "# files.download(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 40\n",
      "Num train: 14984 Num valid: 3746\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_40ld.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 01:23:42.492079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30915 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n",
      "2023-04-27 01:23:42.492737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30916 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2023-04-27 01:23:42.493237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30917 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0\n",
      "2023-04-27 01:23:42.493726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30917 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 01:23:52.926967: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x152c90dabeb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-27 01:23:52.926998: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-04-27 01:23:52.927004: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-04-27 01:23:52.927009: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-04-27 01:23:52.927013: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2023-04-27 01:23:52.931336: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-27 01:23:53.750319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2023-04-27 01:23:53.862086: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - ETA: 0s - loss: 0.4654val_aucs: 0.5241039442160194 0.8957953875823645\n",
      "469/469 [==============================] - 36s 52ms/step - loss: 0.4654 - custom_metric: 1.4199\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4085val_aucs: 0.5396272929586727 0.8999085953822253\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.4085 - custom_metric: 1.4395\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3790val_aucs: 0.538982746378764 0.9011976348636632\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3790 - custom_metric: 1.4402\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3617val_aucs: 0.5527946721265076 0.8931105861948894\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3617 - custom_metric: 1.4459\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3491val_aucs: 0.5429164567380182 0.8969638935019018\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.3491 - custom_metric: 1.4399\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3293val_aucs: 0.5450755471686345 0.8904701478545026\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3293 - custom_metric: 1.4355\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3020val_aucs: 0.5438379788741536 0.8904534070820163\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3020 - custom_metric: 1.4343\n",
      "Epoch 8/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2952val_aucs: 0.5523255301677433 0.8871295267048803\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2952 - custom_metric: 1.4395\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2695val_aucs: 0.5388934621442959 0.8815314123854932\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2695 - custom_metric: 1.4204\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2505val_aucs: 0.514886507583221 0.8833544825092409\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2505 - custom_metric: 1.3982\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2348val_aucs: 0.5152993501066014 0.8801097022821022\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2348 - custom_metric: 1.3954\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2255val_aucs: 0.5027851774506422 0.8767979589650184\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2255 - custom_metric: 1.3796\n",
      "Epoch 13/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2011val_aucs: 0.47929799079699154 0.8760605279370012\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2011 - custom_metric: 1.3554\n",
      "Epoch 14/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1867val_aucs: 0.4600545507804491 0.8676541490330529\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.1867 - custom_metric: 1.3277\n",
      "Test res 0.8860591663739831 0.47436748226682335 0.47732426303854875\n",
      "Repeat 1 ld 40\n",
      "Num train: 14984 Num valid: 3746\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_40ld.h5\n",
      "Epoch 1/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4784val_aucs: 0.5186560128615307 0.895811375161579\n",
      "469/469 [==============================] - 30s 50ms/step - loss: 0.4784 - custom_metric: 1.4145\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4191val_aucs: 0.5462958146498953 0.8993810281396043\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.4191 - custom_metric: 1.4457\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3936val_aucs: 0.5165691883365792 0.8947896987173114\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3936 - custom_metric: 1.4114\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3787val_aucs: 0.5239049713816732 0.8941417254979949\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3787 - custom_metric: 1.4180\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3570val_aucs: 0.5050689365175254 0.8969084551390408\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3570 - custom_metric: 1.4020\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3441val_aucs: 0.49150777480324226 0.8908156839349043\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3441 - custom_metric: 1.3823\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3252val_aucs: 0.520225522778832 0.8976392893838454\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3252 - custom_metric: 1.4179\n",
      "Epoch 8/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2947val_aucs: 0.5140641658097853 0.8879826654734678\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2947 - custom_metric: 1.4020\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2845val_aucs: 0.515325128319886 0.88828013655497\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2845 - custom_metric: 1.4036\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2667val_aucs: 0.4826966188242563 0.8825519538629809\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2667 - custom_metric: 1.3652\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2541val_aucs: 0.5029994780799882 0.890562129196911\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2541 - custom_metric: 1.3936\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2279val_aucs: 0.45675602708667684 0.8656814490736138\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2279 - custom_metric: 1.3224\n",
      "Test res 0.8912502847731782 0.4849925639993627 0.49434389140271495\n",
      "Repeat 2 ld 40\n",
      "Num train: 14984 Num valid: 3746\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_40ld.h5\n",
      "Epoch 1/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4801val_aucs: 0.4745487498775368 0.8915995210164194\n",
      "469/469 [==============================] - 30s 50ms/step - loss: 0.4801 - custom_metric: 1.3661\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4109val_aucs: 0.49477074712222235 0.8977246588595049\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.4109 - custom_metric: 1.3925\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3903val_aucs: 0.4988869155077586 0.8967073261485796\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.3903 - custom_metric: 1.3956\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3682val_aucs: 0.5289322574396926 0.8977948488969171\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3682 - custom_metric: 1.4267\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3481val_aucs: 0.5326211344319636 0.8966641973304108\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3481 - custom_metric: 1.4293\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3289val_aucs: 0.49684494367168375 0.8886549220975152\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3289 - custom_metric: 1.3855\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3182val_aucs: 0.4936522349982265 0.8892240533647244\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3182 - custom_metric: 1.3829\n",
      "Epoch 8/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2983val_aucs: 0.48529850875162744 0.8863361138736104\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2983 - custom_metric: 1.3716\n",
      "Epoch 9/1000\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.2847val_aucs: 0.4929274576141392 0.8796477644050252\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2847 - custom_metric: 1.3726\n",
      "Epoch 10/1000\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.2569val_aucs: 0.4971164368865153 0.8790760961485119\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2568 - custom_metric: 1.3762\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2474val_aucs: 0.47243900906941133 0.8801399403300115\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2474 - custom_metric: 1.3526\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2125val_aucs: 0.4402501615616552 0.8648469688051795\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2125 - custom_metric: 1.3051\n",
      "Epoch 13/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2268val_aucs: 0.4812694319924899 0.8697746476967521\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2268 - custom_metric: 1.3510\n",
      "Epoch 14/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2054val_aucs: 0.4560153289525652 0.8676275090824217\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2054 - custom_metric: 1.3236\n",
      "Epoch 15/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1999val_aucs: 0.4854976151116647 0.8738473611928584\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.1999 - custom_metric: 1.3593\n",
      "Test res 0.8843529004148197 0.4815158505174358 0.49035187287173665\n",
      "Repeat 3 ld 40\n",
      "Num train: 14984 Num valid: 3746\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_40ld.h5\n",
      "Epoch 1/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4599val_aucs: 0.4750465688313171 0.8851889256782958\n",
      "469/469 [==============================] - 29s 49ms/step - loss: 0.4599 - custom_metric: 1.3602\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4061val_aucs: 0.4763287576400841 0.8854343777831754\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.4061 - custom_metric: 1.3618\n",
      "Epoch 3/1000\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.3772val_aucs: 0.47743490473138817 0.8882298045331934\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3773 - custom_metric: 1.3657\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3527val_aucs: 0.4704109262179999 0.8845292731464317\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3527 - custom_metric: 1.3549\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3320val_aucs: 0.4703274216834695 0.8849127920603062\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3320 - custom_metric: 1.3552\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3279val_aucs: 0.4510172629901708 0.8834230341459672\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3279 - custom_metric: 1.3344\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3018val_aucs: 0.4635130034977353 0.8792835866688826\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3018 - custom_metric: 1.3428\n",
      "Epoch 8/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2862val_aucs: 0.46634761223951504 0.8725958690751654\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2862 - custom_metric: 1.3389\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2684val_aucs: 0.4224129265120883 0.8730313761084761\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2684 - custom_metric: 1.2954\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2587val_aucs: 0.39546900564175635 0.8683362523384002\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2587 - custom_metric: 1.2638\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2449val_aucs: 0.42818573216257916 0.8658331522271797\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2449 - custom_metric: 1.2940\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2142val_aucs: 0.4123905928465984 0.8669163800928116\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2142 - custom_metric: 1.2793\n",
      "Epoch 13/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2105val_aucs: 0.40772685629565664 0.8700228832951944\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2105 - custom_metric: 1.2777\n",
      "Test res 0.8912001528282723 0.47426518471018575 0.475\n",
      "Repeat 4 ld 40\n",
      "Num train: 14984 Num valid: 3746\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_40ld.h5\n",
      "Epoch 1/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4875val_aucs: 0.4806775883306412 0.8851331895859003\n",
      "469/469 [==============================] - 30s 50ms/step - loss: 0.4875 - custom_metric: 1.3658\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4074val_aucs: 0.4825825218665498 0.882391888091284\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.4074 - custom_metric: 1.3650\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3872val_aucs: 0.4916081041436261 0.8899444875984357\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3872 - custom_metric: 1.3816\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3716val_aucs: 0.48067225134091535 0.883942920662131\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3716 - custom_metric: 1.3646\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3469val_aucs: 0.4674065570318131 0.8874241643006375\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3469 - custom_metric: 1.3548\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3276val_aucs: 0.48367788375432436 0.885277997267906\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3276 - custom_metric: 1.3690\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3106val_aucs: 0.47310119627678154 0.8784611547115231\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3106 - custom_metric: 1.3516\n",
      "Epoch 8/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2968val_aucs: 0.44235209217210814 0.8789650519633578\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2968 - custom_metric: 1.3213\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2856val_aucs: 0.45583192330485356 0.8828924371886216\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2856 - custom_metric: 1.3387\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2744val_aucs: 0.4145825360326184 0.866683184228853\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2744 - custom_metric: 1.2813\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2589val_aucs: 0.44038977701341153 0.8723838357797182\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2589 - custom_metric: 1.3128\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2264val_aucs: 0.43117268031510575 0.8690394479562865\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2264 - custom_metric: 1.3002\n",
      "Epoch 13/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2226val_aucs: 0.42925430473937837 0.8737992680934269\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2226 - custom_metric: 1.3031\n",
      "Test res 0.8865362801028981 0.4914337623832681 0.4932279909706546\n",
      "Repeat 5 ld 40\n",
      "Num train: 14984 Num valid: 3746\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_40ld.h5\n",
      "Epoch 1/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4667val_aucs: 0.44622174406643544 0.8787774003127066\n",
      "469/469 [==============================] - 30s 50ms/step - loss: 0.4667 - custom_metric: 1.3250\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4109val_aucs: 0.4500075299375194 0.8863724550803367\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.4109 - custom_metric: 1.3364\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3834val_aucs: 0.4737024647945546 0.8883398487852047\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3834 - custom_metric: 1.3620\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3693val_aucs: 0.45988355020975547 0.8834715172248133\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3693 - custom_metric: 1.3434\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3484val_aucs: 0.456284322254155 0.8879527051223505\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3484 - custom_metric: 1.3442\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3428val_aucs: 0.45008069676529805 0.88654578985666\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3428 - custom_metric: 1.3366\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3161val_aucs: 0.4550807942916652 0.8811583338392598\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3161 - custom_metric: 1.3362\n",
      "Epoch 8/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2940val_aucs: 0.4397318885200004 0.8682690894820986\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2940 - custom_metric: 1.3080\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2817val_aucs: 0.43475565124386073 0.8727960307216094\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2817 - custom_metric: 1.3076\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2678val_aucs: 0.44455257216986327 0.8750520224296959\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2678 - custom_metric: 1.3196\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2442val_aucs: 0.4171072853282483 0.8723103413991197\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2442 - custom_metric: 1.2894\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2231val_aucs: 0.39471009210837427 0.8596806592704629\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2231 - custom_metric: 1.2544\n",
      "Epoch 13/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2098val_aucs: 0.39869546238456616 0.8590137163240007\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2098 - custom_metric: 1.2577\n",
      "Test res 0.8785432309415551 0.4584908509588433 0.4717832957110609\n",
      "Repeat 6 ld 40\n",
      "Num train: 14984 Num valid: 3746\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_40ld.h5\n",
      "Epoch 1/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4761val_aucs: 0.4461780878983692 0.87964968774395\n",
      "469/469 [==============================] - 30s 49ms/step - loss: 0.4761 - custom_metric: 1.3258\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4173val_aucs: 0.4653709320836394 0.886471417926336\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.4173 - custom_metric: 1.3518\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3806val_aucs: 0.43532967150895346 0.8832619225037257\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3806 - custom_metric: 1.3186\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3656val_aucs: 0.4237705670863025 0.8802671031154637\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3656 - custom_metric: 1.3040\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3415val_aucs: 0.4267131450455636 0.880801131928181\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.3415 - custom_metric: 1.3075\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3265val_aucs: 0.40367967418983186 0.8727401355475126\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3265 - custom_metric: 1.2764\n",
      "Epoch 7/1000\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.3068val_aucs: 0.4086997820590514 0.8769813178624654\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3069 - custom_metric: 1.2857\n",
      "Epoch 8/1000\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.2871val_aucs: 0.4311198572320141 0.8780901816762473\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2870 - custom_metric: 1.3092\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2620val_aucs: 0.3990181181524992 0.8635072918884394\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2620 - custom_metric: 1.2625\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2490val_aucs: 0.38566968254223044 0.8657649386132993\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2490 - custom_metric: 1.2514\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2446val_aucs: 0.39669754174595306 0.8775579270456321\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2446 - custom_metric: 1.2743\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2135val_aucs: 0.4201678090611122 0.8716117557306081\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2135 - custom_metric: 1.2918\n",
      "Test res 0.888853325201477 0.4835409049728184 0.47959183673469385\n",
      "Repeat 7 ld 40\n",
      "Num train: 14984 Num valid: 3746\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_40ld.h5\n",
      "Epoch 1/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4590val_aucs: 0.46569770884480005 0.8866299047003982\n",
      "469/469 [==============================] - 30s 49ms/step - loss: 0.4590 - custom_metric: 1.3523\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3960val_aucs: 0.46831564117731567 0.8918028910949748\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.3960 - custom_metric: 1.3601\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3771val_aucs: 0.4752985496601375 0.8935848712917195\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.3771 - custom_metric: 1.3689\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3511val_aucs: 0.46507131521312595 0.8925756651606772\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3511 - custom_metric: 1.3576\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3344val_aucs: 0.4768323143250528 0.8946014371757685\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3344 - custom_metric: 1.3714\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3106val_aucs: 0.456250942545004 0.8855204219346399\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3106 - custom_metric: 1.3418\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3014val_aucs: 0.46061876957729786 0.8897651594812478\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3014 - custom_metric: 1.3504\n",
      "Epoch 8/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2848val_aucs: 0.4351929362369846 0.8836160858441591\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2848 - custom_metric: 1.3188\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2556val_aucs: 0.4648361382767434 0.8761054579008328\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2556 - custom_metric: 1.3409\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2493val_aucs: 0.43249025955703696 0.8764798853350482\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2493 - custom_metric: 1.3090\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2208val_aucs: 0.4271964166252405 0.8743216377658366\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2208 - custom_metric: 1.3015\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2030val_aucs: 0.424027510352981 0.868563551007228\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2030 - custom_metric: 1.2926\n",
      "Epoch 13/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1969val_aucs: 0.4277148474485576 0.8646785213888222\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.1969 - custom_metric: 1.2924\n",
      "Epoch 14/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1821val_aucs: 0.4129345086117768 0.8632884480396837\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.1821 - custom_metric: 1.2762\n",
      "Epoch 15/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1665val_aucs: 0.40198422856375643 0.8754191609329591\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.1665 - custom_metric: 1.2774\n",
      "Test res 0.8858258896788708 0.48642290005997046 0.48368953880764903\n",
      "Repeat 8 ld 40\n",
      "Num train: 14984 Num valid: 3746\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_40ld.h5\n",
      "Epoch 1/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4531val_aucs: 0.4637062108679974 0.8851972036829974\n",
      "469/469 [==============================] - 30s 50ms/step - loss: 0.4531 - custom_metric: 1.3489\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3999val_aucs: 0.46603343131651837 0.887079887528209\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.3999 - custom_metric: 1.3531\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3784val_aucs: 0.45984582115281436 0.8873151674134244\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3784 - custom_metric: 1.3472\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3660val_aucs: 0.47124442141555645 0.884361048325332\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3660 - custom_metric: 1.3556\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3444val_aucs: 0.46777872935597936 0.8864354252339233\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3444 - custom_metric: 1.3542\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3261val_aucs: 0.44369430188555115 0.8799667850627073\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3261 - custom_metric: 1.3237\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3107val_aucs: 0.4729716205425649 0.8835097710090705\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3107 - custom_metric: 1.3565\n",
      "Epoch 8/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2963val_aucs: 0.4467973908656575 0.8802745613964861\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2963 - custom_metric: 1.3271\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2815val_aucs: 0.4519185674824326 0.8839202877086052\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2815 - custom_metric: 1.3358\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2639val_aucs: 0.4457567695770759 0.8823738450604124\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2639 - custom_metric: 1.3281\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2489val_aucs: 0.43775100329984895 0.884275653735613\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2489 - custom_metric: 1.3220\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2267val_aucs: 0.43623962690526547 0.8754373136996938\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2267 - custom_metric: 1.3117\n",
      "Epoch 13/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2145val_aucs: 0.4419398994819008 0.8754177441062166\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2145 - custom_metric: 1.3174\n",
      "Epoch 14/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1969val_aucs: 0.42496508447938747 0.8648190301843187\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.1969 - custom_metric: 1.2898\n",
      "Epoch 15/1000\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1850val_aucs: 0.45457699335345564 0.8699427055674605\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.1849 - custom_metric: 1.3245\n",
      "Epoch 16/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1669val_aucs: 0.42166169141471416 0.8682837377567731\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.1669 - custom_metric: 1.2899\n",
      "Epoch 17/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1638val_aucs: 0.4252057156815286 0.8703607832462932\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.1638 - custom_metric: 1.2956\n",
      "Test res 0.8842430254302449 0.4753029396000576 0.4664429530201342\n",
      "Repeat 9 ld 40\n",
      "Num train: 14984 Num valid: 3746\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_40ld.h5\n",
      "Epoch 1/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4819val_aucs: 0.4936784141760397 0.8919706348113767\n",
      "469/469 [==============================] - 30s 50ms/step - loss: 0.4819 - custom_metric: 1.3856\n",
      "Epoch 2/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.4172val_aucs: 0.507892818392613 0.8975443581798016\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.4172 - custom_metric: 1.4054\n",
      "Epoch 3/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3859val_aucs: 0.5117630739537108 0.8972079866802082\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.3859 - custom_metric: 1.4090\n",
      "Epoch 4/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3609val_aucs: 0.49168639467447245 0.8936633150731662\n",
      "469/469 [==============================] - 21s 46ms/step - loss: 0.3609 - custom_metric: 1.3853\n",
      "Epoch 5/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3430val_aucs: 0.49470996689135044 0.8918528831409912\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3430 - custom_metric: 1.3866\n",
      "Epoch 6/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3260val_aucs: 0.5023749575255665 0.8931325667353264\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3260 - custom_metric: 1.3955\n",
      "Epoch 7/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3023val_aucs: 0.4707951013094754 0.8885748844345279\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.3023 - custom_metric: 1.3594\n",
      "Epoch 8/1000\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.2844val_aucs: 0.4833165962273737 0.8800681920702909\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2842 - custom_metric: 1.3634\n",
      "Epoch 9/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2650val_aucs: 0.4661702883182342 0.881182503833423\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2650 - custom_metric: 1.3474\n",
      "Epoch 10/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2346val_aucs: 0.47269384518905755 0.8838552935869496\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2346 - custom_metric: 1.3565\n",
      "Epoch 11/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2245val_aucs: 0.430829225355759 0.8754931933473769\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2245 - custom_metric: 1.3063\n",
      "Epoch 12/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2065val_aucs: 0.46197552500301015 0.8697831031547923\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2065 - custom_metric: 1.3318\n",
      "Epoch 13/1000\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2055val_aucs: 0.4320892198056709 0.869230709289308\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.2055 - custom_metric: 1.3013\n",
      "Test res 0.88714397419955 0.48840740568258717 0.4881087202718007\n",
      "gen_res {40: [(0.8864008229944849, 0.003523852202748347), (0.4798739845151353, 0.009119161014635372), (0.48198643628289944, 0.009007923763934982)]}\n"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60]}\n",
    "lds = [40]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_text_5.h5'\n",
    "f = open('log_text_40.csv', 'a+')\n",
    "f.write('\\nTraining on different % of labeled data\\n')\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2021)\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    f.write('Training on '+str(ld)+' % of labaled data+\\n'+'val_metric,roc_auc,pr_auc,min_rp,savepath\\n')\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "        f.write(str(np.min(his['custom_metric']))+str(rocauc)+str(prauc)+str(minrp)+savepath+'\\n')\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)\n",
    "f.close()\n",
    "\n",
    "# # save to local\n",
    "# log_path = '/content/log.csv'\n",
    "# files.download(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 0 ld 50\n",
      "Num train: 18730 Num valid: 4682\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat0_50ld.h5\n",
      "Epoch 1/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4645val_aucs: 0.528723702020843 0.8954804490736789\n",
      "586/586 [==============================] - 35s 48ms/step - loss: 0.4645 - custom_metric: 1.4242\n",
      "Epoch 2/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4036val_aucs: 0.5189367117889179 0.8990224536839411\n",
      "586/586 [==============================] - 27s 45ms/step - loss: 0.4036 - custom_metric: 1.4180\n",
      "Epoch 3/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3857val_aucs: 0.5298573449581451 0.8995405745752582\n",
      "586/586 [==============================] - 27s 45ms/step - loss: 0.3857 - custom_metric: 1.4294\n",
      "Epoch 4/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3728val_aucs: 0.5149723858337875 0.895785665499872\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3728 - custom_metric: 1.4108\n",
      "Epoch 5/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3590val_aucs: 0.49536766113785907 0.8966452872876293\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3590 - custom_metric: 1.3920\n",
      "Epoch 6/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3409val_aucs: 0.4852627176179846 0.8943086741227696\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3409 - custom_metric: 1.3796\n",
      "Epoch 7/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3264val_aucs: 0.489830931974198 0.891437932212072\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3264 - custom_metric: 1.3813\n",
      "Epoch 8/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3184val_aucs: 0.47966494736529586 0.8889705882352941\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3184 - custom_metric: 1.3686\n",
      "Epoch 9/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2897val_aucs: 0.46497399699556635 0.8812025100315888\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2897 - custom_metric: 1.3462\n",
      "Epoch 10/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2735val_aucs: 0.48242321276003564 0.882951101340391\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2745 - custom_metric: 1.3654\n",
      "Epoch 11/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2595val_aucs: 0.46743097057056976 0.8783541791172201\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2596 - custom_metric: 1.3458\n",
      "Epoch 12/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2332val_aucs: 0.4300048138172264 0.8822793050456758\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2332 - custom_metric: 1.3123\n",
      "Epoch 13/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2282val_aucs: 0.4650133949017521 0.8814372918978913\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2282 - custom_metric: 1.3465\n",
      "Test res 0.8904464531500659 0.4813947169086424 0.49887133182844245\n",
      "Repeat 1 ld 50\n",
      "Num train: 18730 Num valid: 4682\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat1_50ld.h5\n",
      "Epoch 1/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4653val_aucs: 0.50409915744008 0.8891948994122305\n",
      "586/586 [==============================] - 35s 49ms/step - loss: 0.4653 - custom_metric: 1.3933\n",
      "Epoch 2/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4116val_aucs: 0.5288894611675011 0.9003597352008345\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.4116 - custom_metric: 1.4292\n",
      "Epoch 3/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3808val_aucs: 0.5097905529269373 0.8991966405065874\n",
      "586/586 [==============================] - 27s 45ms/step - loss: 0.3808 - custom_metric: 1.4090\n",
      "Epoch 4/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3621val_aucs: 0.5188515887545566 0.8918411990955042\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3622 - custom_metric: 1.4107\n",
      "Epoch 5/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3492val_aucs: 0.4863301424848425 0.8931854985942983\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3492 - custom_metric: 1.3795\n",
      "Epoch 6/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3235val_aucs: 0.4926751461096101 0.889322070253976\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3235 - custom_metric: 1.3820\n",
      "Epoch 7/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3090val_aucs: 0.47663124794658274 0.8870646513635934\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3090 - custom_metric: 1.3637\n",
      "Epoch 8/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2908val_aucs: 0.4960419600257548 0.8839705247461904\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2908 - custom_metric: 1.3800\n",
      "Epoch 9/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2685val_aucs: 0.45555822169754023 0.8718887489827697\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2685 - custom_metric: 1.3274\n",
      "Epoch 10/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2433val_aucs: 0.4708313792178197 0.8797848029206721\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2433 - custom_metric: 1.3506\n",
      "Epoch 11/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2320val_aucs: 0.43841646052219535 0.874446902352988\n",
      "586/586 [==============================] - 27s 46ms/step - loss: 0.2320 - custom_metric: 1.3129\n",
      "Epoch 12/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2289val_aucs: 0.4825296012544299 0.8746979692508544\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2289 - custom_metric: 1.3572\n",
      "Test res 0.8915740956078483 0.4900111763963382 0.4954545454545455\n",
      "Repeat 2 ld 50\n",
      "Num train: 18730 Num valid: 4682\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat2_50ld.h5\n",
      "Epoch 1/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4529val_aucs: 0.49826406139456586 0.8910349306642964\n",
      "586/586 [==============================] - 36s 50ms/step - loss: 0.4529 - custom_metric: 1.3893\n",
      "Epoch 2/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4025val_aucs: 0.48901482892285547 0.8882741615457224\n",
      "586/586 [==============================] - 27s 45ms/step - loss: 0.4025 - custom_metric: 1.3773\n",
      "Epoch 3/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3764val_aucs: 0.503040615966992 0.8938391807957026\n",
      "586/586 [==============================] - 27s 46ms/step - loss: 0.3764 - custom_metric: 1.3969\n",
      "Epoch 4/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3542val_aucs: 0.49265858277492647 0.8910641014703737\n",
      "586/586 [==============================] - 28s 47ms/step - loss: 0.3542 - custom_metric: 1.3837\n",
      "Epoch 5/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3402val_aucs: 0.4996790984111833 0.8920801261499764\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3402 - custom_metric: 1.3918\n",
      "Epoch 6/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3250val_aucs: 0.45805926799235047 0.8834174975301132\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3250 - custom_metric: 1.3415\n",
      "Epoch 7/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3134val_aucs: 0.47954262652363283 0.884649826488743\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3133 - custom_metric: 1.3642\n",
      "Epoch 8/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2941val_aucs: 0.45713953556637615 0.8787138426482689\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2941 - custom_metric: 1.3359\n",
      "Epoch 9/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2712val_aucs: 0.46042104160474134 0.8758694138594352\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2712 - custom_metric: 1.3363\n",
      "Epoch 10/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2596val_aucs: 0.44882108128005394 0.8684055402515845\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2594 - custom_metric: 1.3172\n",
      "Epoch 11/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2531val_aucs: 0.4345899475365573 0.8664191734754815\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2531 - custom_metric: 1.3010\n",
      "Epoch 12/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2307val_aucs: 0.4197556154757275 0.8607600370964591\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2307 - custom_metric: 1.2805\n",
      "Epoch 13/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2184val_aucs: 0.41767931424565075 0.866140674836327\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2184 - custom_metric: 1.2838\n",
      "Test res 0.890104369369797 0.4875024263081219 0.49099099099099097\n",
      "Repeat 3 ld 50\n",
      "Num train: 18730 Num valid: 4682\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat3_50ld.h5\n",
      "Epoch 1/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4588val_aucs: 0.4740803378088544 0.8851838620364884\n",
      "586/586 [==============================] - 36s 48ms/step - loss: 0.4588 - custom_metric: 1.3593\n",
      "Epoch 2/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4065val_aucs: 0.5107533649084216 0.8944861687357405\n",
      "586/586 [==============================] - 27s 46ms/step - loss: 0.4065 - custom_metric: 1.4052\n",
      "Epoch 3/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3807val_aucs: 0.503789077766378 0.8860280008335837\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3807 - custom_metric: 1.3898\n",
      "Epoch 4/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3656val_aucs: 0.49172646359566397 0.8903864526413505\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3656 - custom_metric: 1.3821\n",
      "Epoch 5/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3437val_aucs: 0.48899680798160394 0.8882045202969506\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3437 - custom_metric: 1.3772\n",
      "Epoch 6/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3274val_aucs: 0.47352724460038204 0.8794903231219333\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3274 - custom_metric: 1.3530\n",
      "Epoch 7/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3129val_aucs: 0.4580662611318426 0.8803807420518609\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3130 - custom_metric: 1.3384\n",
      "Epoch 8/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2948val_aucs: 0.4721051927178117 0.874623060497065\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2948 - custom_metric: 1.3467\n",
      "Epoch 9/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2864val_aucs: 0.46237699728912235 0.8712779000186746\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2864 - custom_metric: 1.3337\n",
      "Epoch 10/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2697val_aucs: 0.47043945195976034 0.8815212360855128\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2697 - custom_metric: 1.3520\n",
      "Epoch 11/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2569val_aucs: 0.4474374686639227 0.8733277580658694\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2569 - custom_metric: 1.3208\n",
      "Epoch 12/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2368val_aucs: 0.46842423413738044 0.8750961462993486\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2368 - custom_metric: 1.3435\n",
      "Test res 0.8908882075426922 0.4847798774035013 0.48997772828507796\n",
      "Repeat 4 ld 50\n",
      "Num train: 18730 Num valid: 4682\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat4_50ld.h5\n",
      "Epoch 1/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4608val_aucs: 0.439973109832523 0.8803407065198205\n",
      "586/586 [==============================] - 35s 50ms/step - loss: 0.4608 - custom_metric: 1.3203\n",
      "Epoch 2/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4053val_aucs: 0.5078780078867811 0.8936563459705603\n",
      "586/586 [==============================] - 27s 45ms/step - loss: 0.4053 - custom_metric: 1.4015\n",
      "Epoch 3/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3796val_aucs: 0.48116071312580677 0.8914561933001518\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3796 - custom_metric: 1.3726\n",
      "Epoch 4/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3672val_aucs: 0.5030548190860455 0.8916895010413357\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3672 - custom_metric: 1.3947\n",
      "Epoch 5/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3433val_aucs: 0.48261176208543505 0.8847476305199617\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3433 - custom_metric: 1.3674\n",
      "Epoch 6/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3321val_aucs: 0.5083545167430868 0.8926514128631436\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3321 - custom_metric: 1.4010\n",
      "Epoch 7/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3075val_aucs: 0.4670168793186492 0.8746547266052455\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3075 - custom_metric: 1.3417\n",
      "Epoch 8/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3041val_aucs: 0.4724554417439613 0.8827112896678314\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3041 - custom_metric: 1.3552\n",
      "Epoch 9/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2823val_aucs: 0.4668079148794771 0.8828546939531929\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2823 - custom_metric: 1.3497\n",
      "Epoch 10/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2661val_aucs: 0.440230942151439 0.8716482006071515\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2661 - custom_metric: 1.3119\n",
      "Epoch 11/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2402val_aucs: 0.4427197018327761 0.873569818030993\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2402 - custom_metric: 1.3163\n",
      "Epoch 12/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2246val_aucs: 0.4354904178463937 0.8689742622401073\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2246 - custom_metric: 1.3045\n",
      "Test res 0.8879752152410605 0.5031877909134713 0.5\n",
      "Repeat 5 ld 50\n",
      "Num train: 18730 Num valid: 4682\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat5_50ld.h5\n",
      "Epoch 1/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4662val_aucs: 0.46376825492826573 0.880954772121332\n",
      "586/586 [==============================] - 35s 49ms/step - loss: 0.4662 - custom_metric: 1.3447\n",
      "Epoch 2/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4067val_aucs: 0.4571780916836654 0.8859206823343537\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.4067 - custom_metric: 1.3431\n",
      "Epoch 3/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3891val_aucs: 0.4758730757372794 0.8939869902241533\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3891 - custom_metric: 1.3699\n",
      "Epoch 4/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3744val_aucs: 0.48295132942200547 0.8934809173496593\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3750 - custom_metric: 1.3764\n",
      "Epoch 5/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3567val_aucs: 0.4731391621721015 0.8921702895948724\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3567 - custom_metric: 1.3653\n",
      "Epoch 6/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3400val_aucs: 0.466884910331204 0.8812431551118971\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3399 - custom_metric: 1.3481\n",
      "Epoch 7/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3198val_aucs: 0.4259272970499547 0.880976653321005\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3198 - custom_metric: 1.3069\n",
      "Epoch 8/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3075val_aucs: 0.4492668689885227 0.8843772161727874\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3074 - custom_metric: 1.3336\n",
      "Epoch 9/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2871val_aucs: 0.4735457230127813 0.874250709175292\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2873 - custom_metric: 1.3478\n",
      "Epoch 10/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2839val_aucs: 0.4544397711708907 0.8726848007576505\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2839 - custom_metric: 1.3271\n",
      "Epoch 11/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2540val_aucs: 0.4465842701427139 0.8699524560805049\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2540 - custom_metric: 1.3165\n",
      "Epoch 12/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2462val_aucs: 0.4077437262056583 0.8570885548982469\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2462 - custom_metric: 1.2648\n",
      "Epoch 13/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2230val_aucs: 0.4222683980107781 0.8686076038852034\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2230 - custom_metric: 1.2909\n",
      "Epoch 14/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2173val_aucs: 0.42264657426858027 0.8650813643994003\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2173 - custom_metric: 1.2877\n",
      "Test res 0.8880536465205462 0.4931745112970282 0.47105561861521\n",
      "Repeat 6 ld 50\n",
      "Num train: 18730 Num valid: 4682\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat6_50ld.h5\n",
      "Epoch 1/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4537val_aucs: 0.47920500230187624 0.8902144644812406\n",
      "586/586 [==============================] - 36s 49ms/step - loss: 0.4537 - custom_metric: 1.3694\n",
      "Epoch 2/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3952val_aucs: 0.47778860698718734 0.892195984447275\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3952 - custom_metric: 1.3700\n",
      "Epoch 3/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3805val_aucs: 0.4614432543002061 0.8942059953967508\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3805 - custom_metric: 1.3556\n",
      "Epoch 4/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3597val_aucs: 0.49416798518385097 0.8967930884226052\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3597 - custom_metric: 1.3910\n",
      "Epoch 5/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3495val_aucs: 0.4667071594515658 0.891464715872271\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3495 - custom_metric: 1.3582\n",
      "Epoch 6/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3325val_aucs: 0.454851353707248 0.886169862125986\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3325 - custom_metric: 1.3410\n",
      "Epoch 7/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3140val_aucs: 0.46160020783141503 0.8870558758463498\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3140 - custom_metric: 1.3487\n",
      "Epoch 8/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3046val_aucs: 0.47790523243617317 0.8870502893790083\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3046 - custom_metric: 1.3650\n",
      "Epoch 9/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2839val_aucs: 0.4605112081167535 0.8819599003374226\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2838 - custom_metric: 1.3425\n",
      "Epoch 10/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2747val_aucs: 0.4601782604681447 0.8836151706107126\n",
      "586/586 [==============================] - 27s 45ms/step - loss: 0.2747 - custom_metric: 1.3438\n",
      "Epoch 11/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2500val_aucs: 0.45184145310525625 0.8764253871421869\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2500 - custom_metric: 1.3283\n",
      "Epoch 12/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2341val_aucs: 0.4614771949664313 0.8788934884136669\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2341 - custom_metric: 1.3404\n",
      "Epoch 13/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2199val_aucs: 0.4402963838602243 0.877239056110478\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2198 - custom_metric: 1.3175\n",
      "Epoch 14/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2119val_aucs: 0.42290747454892813 0.8608022725749146\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2119 - custom_metric: 1.2837\n",
      "Test res 0.8926368335121077 0.5006910660559958 0.4971687429218573\n",
      "Repeat 7 ld 50\n",
      "Num train: 18730 Num valid: 4682\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat7_50ld.h5\n",
      "Epoch 1/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4588val_aucs: 0.44361602976272796 0.8743450470468823\n",
      "586/586 [==============================] - 35s 49ms/step - loss: 0.4588 - custom_metric: 1.3180\n",
      "Epoch 2/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3992val_aucs: 0.4686976119998636 0.885554896800297\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3992 - custom_metric: 1.3543\n",
      "Epoch 3/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3803val_aucs: 0.48427392328587765 0.8837443462283275\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3803 - custom_metric: 1.3680\n",
      "Epoch 4/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3686val_aucs: 0.4621333850465258 0.8838915864263572\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3686 - custom_metric: 1.3460\n",
      "Epoch 5/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3509val_aucs: 0.4805733539251143 0.891492091857729\n",
      "586/586 [==============================] - 27s 45ms/step - loss: 0.3509 - custom_metric: 1.3721\n",
      "Epoch 6/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3391val_aucs: 0.4609782346195206 0.8864892842166905\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3391 - custom_metric: 1.3475\n",
      "Epoch 7/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3205val_aucs: 0.46793132672345666 0.8857981510438099\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3205 - custom_metric: 1.3537\n",
      "Epoch 8/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3063val_aucs: 0.45375251591290444 0.886025729524795\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3063 - custom_metric: 1.3398\n",
      "Epoch 9/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2928val_aucs: 0.4485625152776605 0.8804429186702252\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2931 - custom_metric: 1.3290\n",
      "Epoch 10/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2702val_aucs: 0.4402615867687892 0.8780926739883675\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2702 - custom_metric: 1.3184\n",
      "Epoch 11/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2537val_aucs: 0.44201248570096563 0.880863365015169\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2537 - custom_metric: 1.3229\n",
      "Epoch 12/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2463val_aucs: 0.4264366127585537 0.8726044775576266\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2463 - custom_metric: 1.2990\n",
      "Epoch 13/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2230val_aucs: 0.40834420088215423 0.8691233385791152\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2230 - custom_metric: 1.2775\n",
      "Epoch 14/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2109val_aucs: 0.3925710331090185 0.8615933740791191\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2110 - custom_metric: 1.2542\n",
      "Epoch 15/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2134val_aucs: 0.4304555023248755 0.869632800861271\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2134 - custom_metric: 1.3001\n",
      "Test res 0.8867733537737194 0.4784970193558166 0.49204545454545456\n",
      "Repeat 8 ld 50\n",
      "Num train: 18730 Num valid: 4682\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat8_50ld.h5\n",
      "Epoch 1/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4547val_aucs: 0.4770830195819685 0.8900303270020047\n",
      "586/586 [==============================] - 35s 49ms/step - loss: 0.4547 - custom_metric: 1.3671\n",
      "Epoch 2/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3965val_aucs: 0.4906887142860806 0.8930518302292524\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3965 - custom_metric: 1.3837\n",
      "Epoch 3/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3728val_aucs: 0.5070354799594586 0.895176455900441\n",
      "586/586 [==============================] - 27s 45ms/step - loss: 0.3728 - custom_metric: 1.4022\n",
      "Epoch 4/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3605val_aucs: 0.4990818611257952 0.8971364860650869\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3605 - custom_metric: 1.3962\n",
      "Epoch 5/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3479val_aucs: 0.4577675593873447 0.8922982739305911\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3478 - custom_metric: 1.3501\n",
      "Epoch 6/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3298val_aucs: 0.4789951211640599 0.8923917686570966\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3298 - custom_metric: 1.3714\n",
      "Epoch 7/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3135val_aucs: 0.4595224305275901 0.8875826686530097\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3134 - custom_metric: 1.3471\n",
      "Epoch 8/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2982val_aucs: 0.4341293256323835 0.8825429110002985\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2981 - custom_metric: 1.3167\n",
      "Epoch 9/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2844val_aucs: 0.4530998511667658 0.8833558112571009\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2843 - custom_metric: 1.3365\n",
      "Epoch 10/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2617val_aucs: 0.4683622064238865 0.8848153367181782\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2619 - custom_metric: 1.3532\n",
      "Epoch 11/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2503val_aucs: 0.4559664283012137 0.8740208946717524\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2503 - custom_metric: 1.3300\n",
      "Epoch 12/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2287val_aucs: 0.4359555129835264 0.8752609594574393\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2287 - custom_metric: 1.3112\n",
      "Epoch 13/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2144val_aucs: 0.4384865628612525 0.8733753891648008\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2144 - custom_metric: 1.3119\n",
      "Test res 0.8879370081729903 0.4955804813287131 0.48409090909090907\n",
      "Repeat 9 ld 50\n",
      "Num train: 18730 Num valid: 4682\n",
      "new_mimic_iii_24hm_strats_no_interp_with_ss_repeat9_50ld.h5\n",
      "Epoch 1/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.4550val_aucs: 0.4899136406248855 0.8904171824272463\n",
      "586/586 [==============================] - 35s 50ms/step - loss: 0.4550 - custom_metric: 1.3803\n",
      "Epoch 2/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3995val_aucs: 0.5144982721548419 0.8966454987887673\n",
      "586/586 [==============================] - 27s 45ms/step - loss: 0.3995 - custom_metric: 1.4111\n",
      "Epoch 3/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3741val_aucs: 0.496885756603694 0.8982293106527443\n",
      "586/586 [==============================] - 27s 45ms/step - loss: 0.3741 - custom_metric: 1.3951\n",
      "Epoch 4/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3598val_aucs: 0.5104430563268358 0.8965508843649385\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3598 - custom_metric: 1.4070\n",
      "Epoch 5/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3443val_aucs: 0.5010928163853964 0.8959199349231917\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3443 - custom_metric: 1.3970\n",
      "Epoch 6/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.3215val_aucs: 0.4956932510370317 0.8927030445130072\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3215 - custom_metric: 1.3884\n",
      "Epoch 7/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.3068val_aucs: 0.44752652821118183 0.8840312686674539\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.3067 - custom_metric: 1.3316\n",
      "Epoch 8/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2896val_aucs: 0.4871264196124256 0.8860290886167652\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2896 - custom_metric: 1.3732\n",
      "Epoch 9/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2696val_aucs: 0.4921304065628072 0.8894441654531946\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2695 - custom_metric: 1.3816\n",
      "Epoch 10/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2548val_aucs: 0.4537977978873876 0.8844542343313755\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2547 - custom_metric: 1.3383\n",
      "Epoch 11/1000\n",
      "585/586 [============================>.] - ETA: 0s - loss: 0.2445val_aucs: 0.46320284245743454 0.8800750980994817\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2444 - custom_metric: 1.3433\n",
      "Epoch 12/1000\n",
      "586/586 [==============================] - ETA: 0s - loss: 0.2177val_aucs: 0.4571199187976397 0.8784845680515643\n",
      "586/586 [==============================] - 26s 45ms/step - loss: 0.2177 - custom_metric: 1.3356\n",
      "Test res 0.8902213043560804 0.4966143313036223 0.49772727272727274\n",
      "gen_res {50: [(0.8896610487246909, 0.0017856403964754605), (0.4911433397271251, 0.007745774833207879), (0.49173825944597616, 0.008296457914600855)]}\n"
     ]
    }
   ],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60]}\n",
    "lds = [50]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_text_5.h5'\n",
    "f = open('log_text_50.csv', 'a+')\n",
    "f.write('\\nTraining on different % of labeled data\\n')\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2021)\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    f.write('Training on '+str(ld)+' % of labaled data+\\n'+'val_metric,roc_auc,pr_auc,min_rp,savepath\\n')\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "        f.write(str(np.min(his['custom_metric']))+str(rocauc)+str(prauc)+str(minrp)+savepath+'\\n')\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)\n",
    "f.close()\n",
    "\n",
    "# # save to local\n",
    "# log_path = '/content/log.csv'\n",
    "# files.download(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60]}\n",
    "lds = [90]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_text_5.h5'\n",
    "f = open('log_text_90.csv', 'a+')\n",
    "f.write('\\nTraining on different % of labeled data\\n')\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2021)\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    f.write('Training on '+str(ld)+' % of labaled data+\\n'+'val_metric,roc_auc,pr_auc,min_rp,savepath\\n')\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "        f.write(str(np.min(his['custom_metric']))+str(rocauc)+str(prauc)+str(minrp)+savepath+'\\n')\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)\n",
    "f.close()\n",
    "\n",
    "# # save to local\n",
    "# log_path = '/content/log.csv'\n",
    "# files.download(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repeats = {k:10 for k in [10,20,30,40,50,60]}\n",
    "lds = [100]\n",
    "batch_size, lr, patience = 32, 0.0005, 10\n",
    "d, N, he, dropout = 50,2,4,0.2\n",
    "fore_savepath = 'mimic_iii_24h_strats_no_interp_with_ss_fore_text_5.h5'\n",
    "f = open('log_text_100.csv', 'a+')\n",
    "f.write('\\nTraining on different % of labeled data\\n')\n",
    "\n",
    "train_inds = np.arange(len(train_op))\n",
    "valid_inds = np.arange(len(valid_op))\n",
    "gen_res = {}\n",
    "\n",
    "np.random.seed(2021)\n",
    "for ld in lds:\n",
    "    np.random.shuffle(train_inds)\n",
    "    np.random.shuffle(valid_inds)\n",
    "    train_starts = [int(i) for i in np.linspace(0, len(train_inds)-int(ld*len(train_inds)/100), repeats[ld])]\n",
    "    valid_starts = [int(i) for i in np.linspace(0, len(valid_inds)-int(ld*len(valid_inds)/100), repeats[ld])]\n",
    "    f.write('Training on '+str(ld)+' % of labaled data+\\n'+'val_metric,roc_auc,pr_auc,min_rp,savepath\\n')\n",
    "    all_test_res = []\n",
    "    for i in range(repeats[ld]):\n",
    "        print ('Repeat', i, 'ld', ld)\n",
    "        # Get train and validation data.\n",
    "        curr_train_ind = train_inds[np.arange(train_starts[i], train_starts[i]+int(ld*len(train_inds)/100))]\n",
    "        curr_valid_ind = valid_inds[np.arange(valid_starts[i], valid_starts[i]+int(ld*len(valid_inds)/100))]\n",
    "        curr_train_ip = [ip[curr_train_ind] for ip in train_ip]\n",
    "        curr_valid_ip = [ip[curr_valid_ind] for ip in valid_ip]\n",
    "        curr_train_op = train_op[curr_train_ind]\n",
    "        curr_valid_op = valid_op[curr_valid_ind]\n",
    "        print ('Num train:',len(curr_train_op),'Num valid:',len(curr_valid_op))\n",
    "        # Construct save_path.\n",
    "        savepath = 'new_mimic_iii_24hm_strats_no_interp_with_ss_repeat'+str(i)+'_'+str(ld)+'ld'+'.h5'\n",
    "        print (savepath)\n",
    "        # Build and compile model.\n",
    "        model, fore_model =  build_strats(D, max_len, V, d, N, he, dropout, forecast=True)\n",
    "        model.compile(loss=mortality_loss, optimizer=Adam(lr))\n",
    "        fore_model.compile(loss=forecast_loss, optimizer=Adam(lr))\n",
    "        # Load pretrained weights here.\n",
    "        fore_model.load_weights(fore_savepath)\n",
    "        # Train model.\n",
    "        es = EarlyStopping(monitor='custom_metric', patience=patience, mode='max', \n",
    "                           restore_best_weights=True)\n",
    "        cus = CustomCallback(validation_data=(curr_valid_ip, curr_valid_op), batch_size=batch_size)\n",
    "        his = model.fit(curr_train_ip, curr_train_op, batch_size=batch_size, epochs=1000,\n",
    "                        verbose=1, callbacks=[cus, es]).history\n",
    "        model.save_weights(savepath)\n",
    "        # Test and write to log.\n",
    "        rocauc, prauc, minrp = get_res(test_op, model.predict(test_ip, verbose=0, batch_size=batch_size))\n",
    "        f.write(str(np.min(his['custom_metric']))+str(rocauc)+str(prauc)+str(minrp)+savepath+'\\n')\n",
    "        print ('Test res', rocauc, prauc, minrp)\n",
    "        all_test_res.append([rocauc, prauc, minrp])\n",
    "        \n",
    "    gen_res[ld] = []\n",
    "    for i in range(len(all_test_res[0])):\n",
    "        nums = [test_res[i] for test_res in all_test_res]\n",
    "        gen_res[ld].append((np.mean(nums), np.std(nums)))\n",
    "    print ('gen_res', gen_res)\n",
    "f.close()\n",
    "\n",
    "# # save to local\n",
    "# log_path = '/content/log.csv'\n",
    "# files.download(log_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
